{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flowers_Recognition.ipynb",
      "provenance": [],
      "mount_file_id": "1OMdGaCqTN9gwqdqYLngh3rUyqyw5aviQ",
      "authorship_tag": "ABX9TyNsTaOYFpRrV7SeodGBTcgP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kahmed92/AI-Q2-learning-resources/blob/master/Flowers_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaQa_ax4VnXj"
      },
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, os, cv2\n",
        "from zipfile import ZipFile\n",
        "from pathlib import Path"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkXMM9-tXMeC",
        "outputId": "78062f4d-4c3e-4c8d-88aa-b8a2acf61052"
      },
      "source": [
        "file_name = \"/content/drive/MyDrive/flowers.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM9e8lY1Xfqu",
        "outputId": "d5ff4d29-270a-4f99-94e9-02052448849d"
      },
      "source": [
        "directory = Path(\"/content/flowers\")\n",
        "flowers = []\n",
        "features = []\n",
        "labels = []\n",
        "for dir in directory.iterdir():\n",
        "  flowers.append(dir.name)\n",
        "  print(dir.name)\n",
        "  for imgpath in dir.iterdir():\n",
        "    if imgpath.name.endswith(\"jpg\"):\n",
        "      labels.append(dir.name)\n",
        "      imgarr = cv2.imread(str(imgpath), cv2.IMREAD_GRAYSCALE)\n",
        "      imgarr = cv2.resize(imgarr, (150,150))\n",
        "      features.append(imgarr)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flowers\n",
            "rose\n",
            "daisy\n",
            "tulip\n",
            "dandelion\n",
            "sunflower\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxnKwTjZYU2Z"
      },
      "source": [
        "!cd flowers"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK_nd2-1Yy1X",
        "outputId": "669bb1f3-da49-42b4-a80b-15d62ca2ab16"
      },
      "source": [
        "!ls -ltrh"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12K\n",
            "drwxr-xr-x 1 root root 4.0K Apr 21 13:39 sample_data\n",
            "drwx------ 5 root root 4.0K Apr 24 05:32 drive\n",
            "drwxr-xr-x 8 root root 4.0K Apr 24 05:32 flowers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwrwUynmY0ln",
        "outputId": "6b82f377-7407-4f3e-8a19-28125506137c"
      },
      "source": [
        "!cd flowers\n",
        "!ls -ltrh"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12K\n",
            "drwxr-xr-x 1 root root 4.0K Apr 21 13:39 sample_data\n",
            "drwx------ 5 root root 4.0K Apr 24 05:32 drive\n",
            "drwxr-xr-x 8 root root 4.0K Apr 24 05:32 flowers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6keElDs1Y59L",
        "outputId": "60092fbf-a9ec-4db6-fc00-ccaa8d581ae2"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKFZ2sE3Y_m5"
      },
      "source": [
        "rm -rf /content/flowers/flowers"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpPlWLEtZJC5",
        "outputId": "54ede106-dd59-4747-c482-e9e2490345ad"
      },
      "source": [
        "directory = Path(\"/content/flowers\")\n",
        "flowers = []\n",
        "features = []\n",
        "labels = []\n",
        "for dir in directory.iterdir():\n",
        "  flowers.append(dir.name)\n",
        "  print(dir.name)\n",
        "  for imgpath in dir.iterdir():\n",
        "    if imgpath.name.endswith(\"jpg\"):\n",
        "      labels.append(dir.name)\n",
        "      imgarr = cv2.imread(str(imgpath), cv2.IMREAD_GRAYSCALE)\n",
        "      imgarr = cv2.resize(imgarr, (150,150))\n",
        "      features.append(imgarr)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rose\n",
            "daisy\n",
            "tulip\n",
            "dandelion\n",
            "sunflower\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoAdH4-AZPts",
        "outputId": "a63f5b2a-5046-451c-fa40-1d2cc6899559"
      },
      "source": [
        "train = np.asarray(features)\n",
        "train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323, 150, 150)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0NbTpAMZljU",
        "outputId": "333f5d46-93b4-4ebc-c16c-9a32d71c3806"
      },
      "source": [
        "labels = np.asarray(labels)\n",
        "labels.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au4VhczdZmNE"
      },
      "source": [
        "label_dummies = pd.get_dummies(labels)\n",
        "\n",
        "labels =  label_dummies.values.argmax(1)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhdxzmjzbH0p",
        "outputId": "be580886-f5fe-4b91-d14a-cbfa9997fa3a"
      },
      "source": [
        "pd.unique(labels)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 4, 1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uPqTavXbOAw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_labels, test_labels=train_test_split(train, labels, test_size=0.4, random_state=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7QAo3dAbVkg",
        "outputId": "3872f0e9-cc41-47e8-97b5-b19b9d118061"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_data.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2593, 150, 150)\n",
            "(2593,)\n",
            "(1730, 150, 150)\n",
            "(1730,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-icPLGGbXCg"
      },
      "source": [
        "train_images=train_data.reshape((2593,150*150))\n",
        "train_images=train_images.astype('float32')/255\n",
        "test_images=test_data.reshape((1730,150*150))\n",
        "test_images=test_images.astype('float32')/255"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqNjiPzFcOCk"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzv9jMeYckUd"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "network = models.Sequential()\n",
        "\n",
        "network.add(layers.Dense(512, activation= 'relu', input_shape=(150*150,)))\n",
        "network.add(layers.Dense(5, activation='softmax'))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxHwb3YLcvk9"
      },
      "source": [
        "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF_Ftd8Geen4",
        "outputId": "746290c1-4b32-4a8c-a708-10b46cd5d909"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=25, batch_size=128)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 67.8418 - accuracy: 0.2127\n",
            "Epoch 2/25\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 13.5490 - accuracy: 0.2263\n",
            "Epoch 3/25\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 10.3683 - accuracy: 0.2437\n",
            "Epoch 4/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 12.0344 - accuracy: 0.2421\n",
            "Epoch 5/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 9.3900 - accuracy: 0.2448\n",
            "Epoch 6/25\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 11.4748 - accuracy: 0.2233\n",
            "Epoch 7/25\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 7.7658 - accuracy: 0.2515\n",
            "Epoch 8/25\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 7.2097 - accuracy: 0.2372\n",
            "Epoch 9/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 6.2533 - accuracy: 0.2507\n",
            "Epoch 10/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 6.0442 - accuracy: 0.2290\n",
            "Epoch 11/25\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 4.2126 - accuracy: 0.2731\n",
            "Epoch 12/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 6.4723 - accuracy: 0.2052\n",
            "Epoch 13/25\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 3.7708 - accuracy: 0.2702\n",
            "Epoch 14/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 3.6449 - accuracy: 0.2476\n",
            "Epoch 15/25\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 2.9237 - accuracy: 0.2907\n",
            "Epoch 16/25\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 4.0400 - accuracy: 0.2589\n",
            "Epoch 17/25\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 3.3247 - accuracy: 0.2693\n",
            "Epoch 18/25\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 2.5831 - accuracy: 0.2949\n",
            "Epoch 19/25\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 2.1706 - accuracy: 0.3091\n",
            "Epoch 20/25\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 2.3805 - accuracy: 0.3130\n",
            "Epoch 21/25\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 2.5435 - accuracy: 0.3078\n",
            "Epoch 22/25\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 2.6364 - accuracy: 0.2803\n",
            "Epoch 23/25\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 2.6269 - accuracy: 0.2916\n",
            "Epoch 24/25\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 2.2537 - accuracy: 0.3127\n",
            "Epoch 25/25\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 2.1822 - accuracy: 0.3191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oizjEWNpe7Nn"
      },
      "source": [
        "from keras import regularizers\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.02),input_shape=(150*150,)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(256,kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0d5qXmufCaH",
        "outputId": "115bb40a-0195-4b78-dfa9-bd8d11d69876"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=25, batch_size=128)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 2.2921 - accuracy: 0.2962\n",
            "Epoch 2/25\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 1.9768 - accuracy: 0.3216\n",
            "Epoch 3/25\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 1.9179 - accuracy: 0.3452\n",
            "Epoch 4/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.9164 - accuracy: 0.3255\n",
            "Epoch 5/25\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 2.3724 - accuracy: 0.3132\n",
            "Epoch 6/25\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 1.8438 - accuracy: 0.3536\n",
            "Epoch 7/25\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 1.7559 - accuracy: 0.3475\n",
            "Epoch 8/25\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 1.6560 - accuracy: 0.3806\n",
            "Epoch 9/25\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 1.8009 - accuracy: 0.3482\n",
            "Epoch 10/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.7137 - accuracy: 0.3529\n",
            "Epoch 11/25\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.6613 - accuracy: 0.3772\n",
            "Epoch 12/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.6169 - accuracy: 0.3810\n",
            "Epoch 13/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.5241 - accuracy: 0.3984\n",
            "Epoch 14/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.5852 - accuracy: 0.3953\n",
            "Epoch 15/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.4673 - accuracy: 0.4173\n",
            "Epoch 16/25\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.4527 - accuracy: 0.4250\n",
            "Epoch 17/25\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.4526 - accuracy: 0.4049\n",
            "Epoch 18/25\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 1.3809 - accuracy: 0.4319\n",
            "Epoch 19/25\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 1.4213 - accuracy: 0.4134\n",
            "Epoch 20/25\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 1.4601 - accuracy: 0.4173\n",
            "Epoch 21/25\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 1.3789 - accuracy: 0.4447\n",
            "Epoch 22/25\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 1.3356 - accuracy: 0.4504\n",
            "Epoch 23/25\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 1.3283 - accuracy: 0.4570\n",
            "Epoch 24/25\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 1.3025 - accuracy: 0.4400\n",
            "Epoch 25/25\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 1.3639 - accuracy: 0.4493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmKC5ekIfjRa"
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(1024, activation='relu',kernel_regularizer=regularizers.l2(0.02),input_shape=(150*150,)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512,kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(256,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(64,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(32,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owFvx8cOgHIq",
        "outputId": "1b8648b3-6988-488d-9f4b-568ff6b85122"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=50, batch_size=128)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.2526 - accuracy: 0.4755\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.4027 - accuracy: 0.4574\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.2569 - accuracy: 0.4948\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.2838 - accuracy: 0.4778\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.3100 - accuracy: 0.4466\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.2589 - accuracy: 0.4670\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.3106 - accuracy: 0.4589\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.2173 - accuracy: 0.4990\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.2338 - accuracy: 0.5102\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.3202 - accuracy: 0.4913\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.2706 - accuracy: 0.4925\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.1848 - accuracy: 0.5067\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.1997 - accuracy: 0.5187\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.1521 - accuracy: 0.5260\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.1892 - accuracy: 0.5241\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.0922 - accuracy: 0.5573\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.2353 - accuracy: 0.5349\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.1248 - accuracy: 0.5499\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 1.2903 - accuracy: 0.5272\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.0486 - accuracy: 0.5793\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.1016 - accuracy: 0.5677\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.0861 - accuracy: 0.5607\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.1010 - accuracy: 0.5804\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.1484 - accuracy: 0.5677\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.1021 - accuracy: 0.5553\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 1.0510 - accuracy: 0.5843\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 1.0643 - accuracy: 0.5889\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.1614 - accuracy: 0.5638\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 1.2247 - accuracy: 0.5600\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 1.0049 - accuracy: 0.5951\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.0356 - accuracy: 0.5993\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 1.0831 - accuracy: 0.5970\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.0139 - accuracy: 0.6051\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.0302 - accuracy: 0.6016\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 1.0303 - accuracy: 0.5893\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.9796 - accuracy: 0.6190\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.0245 - accuracy: 0.6028\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.0191 - accuracy: 0.6012\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 1.0019 - accuracy: 0.6093\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 1.0008 - accuracy: 0.6267\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.9432 - accuracy: 0.6402\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 1.0506 - accuracy: 0.6151\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.9129 - accuracy: 0.6572\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 1.0895 - accuracy: 0.6236\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.9644 - accuracy: 0.6255\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.9037 - accuracy: 0.6498\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.9643 - accuracy: 0.6425\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.9543 - accuracy: 0.6440\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.9505 - accuracy: 0.6529\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.8885 - accuracy: 0.6726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqjgp2R9hMQh"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(1024, activation='relu',input_shape=(150*150,)))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO_f_J-zhYIS",
        "outputId": "51a5766e-42ff-437e-dd6e-66ec8e3f86fd"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=200, batch_size=64)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.9778 - accuracy: 0.6452\n",
            "Epoch 2/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 1.0153 - accuracy: 0.6194\n",
            "Epoch 3/200\n",
            "41/41 [==============================] - 5s 123ms/step - loss: 1.0418 - accuracy: 0.6240\n",
            "Epoch 4/200\n",
            "41/41 [==============================] - 5s 123ms/step - loss: 1.1274 - accuracy: 0.6267\n",
            "Epoch 5/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.8890 - accuracy: 0.6726\n",
            "Epoch 6/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.9277 - accuracy: 0.6568\n",
            "Epoch 7/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 1.0088 - accuracy: 0.6356\n",
            "Epoch 8/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.8251 - accuracy: 0.6953\n",
            "Epoch 9/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.9565 - accuracy: 0.6629\n",
            "Epoch 10/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.9985 - accuracy: 0.6649\n",
            "Epoch 11/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.8467 - accuracy: 0.6903\n",
            "Epoch 12/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.8588 - accuracy: 0.6849\n",
            "Epoch 13/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.8735 - accuracy: 0.6853\n",
            "Epoch 14/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.8802 - accuracy: 0.6718\n",
            "Epoch 15/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.8719 - accuracy: 0.6888\n",
            "Epoch 16/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.8278 - accuracy: 0.7023\n",
            "Epoch 17/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.8109 - accuracy: 0.6946\n",
            "Epoch 18/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.8472 - accuracy: 0.6992\n",
            "Epoch 19/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.8786 - accuracy: 0.6834\n",
            "Epoch 20/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.7850 - accuracy: 0.7262\n",
            "Epoch 21/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.7701 - accuracy: 0.7262\n",
            "Epoch 22/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.9202 - accuracy: 0.6992\n",
            "Epoch 23/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.7382 - accuracy: 0.7331\n",
            "Epoch 24/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.8357 - accuracy: 0.7208\n",
            "Epoch 25/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.8690 - accuracy: 0.7119\n",
            "Epoch 26/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.7540 - accuracy: 0.7385\n",
            "Epoch 27/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.7613 - accuracy: 0.7246\n",
            "Epoch 28/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.7280 - accuracy: 0.7343\n",
            "Epoch 29/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.7726 - accuracy: 0.7385\n",
            "Epoch 30/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.7871 - accuracy: 0.7258\n",
            "Epoch 31/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.7227 - accuracy: 0.7578\n",
            "Epoch 32/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.9508 - accuracy: 0.7088\n",
            "Epoch 33/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.7044 - accuracy: 0.7547\n",
            "Epoch 34/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.7843 - accuracy: 0.7358\n",
            "Epoch 35/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.9028 - accuracy: 0.7196\n",
            "Epoch 36/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.6893 - accuracy: 0.7570\n",
            "Epoch 37/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.6879 - accuracy: 0.7617\n",
            "Epoch 38/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.6898 - accuracy: 0.7482\n",
            "Epoch 39/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.7049 - accuracy: 0.7682\n",
            "Epoch 40/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.7521 - accuracy: 0.7424\n",
            "Epoch 41/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.7301 - accuracy: 0.7486\n",
            "Epoch 42/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.7141 - accuracy: 0.7667\n",
            "Epoch 43/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.6332 - accuracy: 0.7867\n",
            "Epoch 44/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.6563 - accuracy: 0.7709\n",
            "Epoch 45/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.7470 - accuracy: 0.7327\n",
            "Epoch 46/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.5620 - accuracy: 0.8010\n",
            "Epoch 47/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.6930 - accuracy: 0.7644\n",
            "Epoch 48/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.6644 - accuracy: 0.7694\n",
            "Epoch 49/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.6381 - accuracy: 0.7798\n",
            "Epoch 50/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.7170 - accuracy: 0.7856\n",
            "Epoch 51/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.6213 - accuracy: 0.7755\n",
            "Epoch 52/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.6582 - accuracy: 0.7705\n",
            "Epoch 53/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.6093 - accuracy: 0.7863\n",
            "Epoch 54/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.6745 - accuracy: 0.7871\n",
            "Epoch 55/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.5776 - accuracy: 0.8010\n",
            "Epoch 56/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.6309 - accuracy: 0.7825\n",
            "Epoch 57/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.6063 - accuracy: 0.7956\n",
            "Epoch 58/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.5628 - accuracy: 0.8052\n",
            "Epoch 59/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.5310 - accuracy: 0.8091\n",
            "Epoch 60/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.6560 - accuracy: 0.7898\n",
            "Epoch 61/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.5852 - accuracy: 0.8126\n",
            "Epoch 62/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.5981 - accuracy: 0.7948\n",
            "Epoch 63/200\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.6262 - accuracy: 0.7944\n",
            "Epoch 64/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.5817 - accuracy: 0.8049\n",
            "Epoch 65/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.5520 - accuracy: 0.8187\n",
            "Epoch 66/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.5487 - accuracy: 0.8211\n",
            "Epoch 67/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.6094 - accuracy: 0.8164\n",
            "Epoch 68/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.6545 - accuracy: 0.8022\n",
            "Epoch 69/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.5427 - accuracy: 0.8187\n",
            "Epoch 70/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.5468 - accuracy: 0.8214\n",
            "Epoch 71/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.6134 - accuracy: 0.8176\n",
            "Epoch 72/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.5609 - accuracy: 0.8230\n",
            "Epoch 73/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.5304 - accuracy: 0.8303\n",
            "Epoch 74/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.5483 - accuracy: 0.8153\n",
            "Epoch 75/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4840 - accuracy: 0.8307\n",
            "Epoch 76/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.4963 - accuracy: 0.8303\n",
            "Epoch 77/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.5367 - accuracy: 0.8222\n",
            "Epoch 78/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.5810 - accuracy: 0.8234\n",
            "Epoch 79/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.8374 - accuracy: 0.8203\n",
            "Epoch 80/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.4287 - accuracy: 0.8604\n",
            "Epoch 81/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.5337 - accuracy: 0.8388\n",
            "Epoch 82/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.4361 - accuracy: 0.8546\n",
            "Epoch 83/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.4815 - accuracy: 0.8427\n",
            "Epoch 84/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.5568 - accuracy: 0.8280\n",
            "Epoch 85/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.4792 - accuracy: 0.8469\n",
            "Epoch 86/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.4327 - accuracy: 0.8538\n",
            "Epoch 87/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.4407 - accuracy: 0.8565\n",
            "Epoch 88/200\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.5341 - accuracy: 0.8423\n",
            "Epoch 89/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.5337 - accuracy: 0.8442\n",
            "Epoch 90/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4711 - accuracy: 0.8508\n",
            "Epoch 91/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.4817 - accuracy: 0.8450\n",
            "Epoch 92/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.4339 - accuracy: 0.8592\n",
            "Epoch 93/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.5801 - accuracy: 0.8419\n",
            "Epoch 94/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.6882 - accuracy: 0.8319\n",
            "Epoch 95/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3940 - accuracy: 0.8681\n",
            "Epoch 96/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.5477 - accuracy: 0.8546\n",
            "Epoch 97/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4998 - accuracy: 0.8419\n",
            "Epoch 98/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.4234 - accuracy: 0.8716\n",
            "Epoch 99/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.5084 - accuracy: 0.8484\n",
            "Epoch 100/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.5081 - accuracy: 0.8373\n",
            "Epoch 101/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.6270 - accuracy: 0.8696\n",
            "Epoch 102/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.4689 - accuracy: 0.8481\n",
            "Epoch 103/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.4443 - accuracy: 0.8639\n",
            "Epoch 104/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.5406 - accuracy: 0.8461\n",
            "Epoch 105/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.6219 - accuracy: 0.8689\n",
            "Epoch 106/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4061 - accuracy: 0.8816\n",
            "Epoch 107/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.5927 - accuracy: 0.8781\n",
            "Epoch 108/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.4087 - accuracy: 0.8723\n",
            "Epoch 109/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4246 - accuracy: 0.8785\n",
            "Epoch 110/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4828 - accuracy: 0.8700\n",
            "Epoch 111/200\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.4515 - accuracy: 0.8696\n",
            "Epoch 112/200\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.4238 - accuracy: 0.8777\n",
            "Epoch 113/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4440 - accuracy: 0.8562\n",
            "Epoch 114/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.4269 - accuracy: 0.8704\n",
            "Epoch 115/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.4375 - accuracy: 0.8731\n",
            "Epoch 116/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.4536 - accuracy: 0.8723\n",
            "Epoch 117/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.4261 - accuracy: 0.8673\n",
            "Epoch 118/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.5654 - accuracy: 0.8457\n",
            "Epoch 119/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.3299 - accuracy: 0.8951\n",
            "Epoch 120/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.3793 - accuracy: 0.8754\n",
            "Epoch 121/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.6790 - accuracy: 0.8427\n",
            "Epoch 122/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.2861 - accuracy: 0.9101\n",
            "Epoch 123/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.5432 - accuracy: 0.8527\n",
            "Epoch 124/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.3819 - accuracy: 0.9040\n",
            "Epoch 125/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.3659 - accuracy: 0.8866\n",
            "Epoch 126/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.7150 - accuracy: 0.8573\n",
            "Epoch 127/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.3536 - accuracy: 0.8974\n",
            "Epoch 128/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.3862 - accuracy: 0.8897\n",
            "Epoch 129/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.4619 - accuracy: 0.8700\n",
            "Epoch 130/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.3231 - accuracy: 0.8920\n",
            "Epoch 131/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.4957 - accuracy: 0.8901\n",
            "Epoch 132/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.5423 - accuracy: 0.8801\n",
            "Epoch 133/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.4690 - accuracy: 0.8739\n",
            "Epoch 134/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.2971 - accuracy: 0.9082\n",
            "Epoch 135/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3723 - accuracy: 0.8897\n",
            "Epoch 136/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.3288 - accuracy: 0.8966\n",
            "Epoch 137/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.3616 - accuracy: 0.8978\n",
            "Epoch 138/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.6381 - accuracy: 0.8793\n",
            "Epoch 139/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.4268 - accuracy: 0.8812\n",
            "Epoch 140/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.4782 - accuracy: 0.8862\n",
            "Epoch 141/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.4521 - accuracy: 0.9013\n",
            "Epoch 142/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.4421 - accuracy: 0.8878\n",
            "Epoch 143/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.5175 - accuracy: 0.8797\n",
            "Epoch 144/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.3129 - accuracy: 0.9117\n",
            "Epoch 145/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.3926 - accuracy: 0.8843\n",
            "Epoch 146/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.3906 - accuracy: 0.9017\n",
            "Epoch 147/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.6296 - accuracy: 0.8700\n",
            "Epoch 148/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.2943 - accuracy: 0.9236\n",
            "Epoch 149/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.4288 - accuracy: 0.8970\n",
            "Epoch 150/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3656 - accuracy: 0.9071\n",
            "Epoch 151/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4546 - accuracy: 0.8943\n",
            "Epoch 152/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.2493 - accuracy: 0.9175\n",
            "Epoch 153/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4554 - accuracy: 0.8912\n",
            "Epoch 154/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.4703 - accuracy: 0.8990\n",
            "Epoch 155/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.3880 - accuracy: 0.8993\n",
            "Epoch 156/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.3299 - accuracy: 0.9113\n",
            "Epoch 157/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.4803 - accuracy: 0.8874\n",
            "Epoch 158/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.3222 - accuracy: 0.9078\n",
            "Epoch 159/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4081 - accuracy: 0.8882\n",
            "Epoch 160/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.2882 - accuracy: 0.9190\n",
            "Epoch 161/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.4989 - accuracy: 0.8781\n",
            "Epoch 162/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.3365 - accuracy: 0.9140\n",
            "Epoch 163/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3280 - accuracy: 0.8990\n",
            "Epoch 164/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3772 - accuracy: 0.9117\n",
            "Epoch 165/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4204 - accuracy: 0.9036\n",
            "Epoch 166/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3795 - accuracy: 0.9036\n",
            "Epoch 167/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.6062 - accuracy: 0.8916\n",
            "Epoch 168/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.2637 - accuracy: 0.9252\n",
            "Epoch 169/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.5100 - accuracy: 0.8855\n",
            "Epoch 170/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.2904 - accuracy: 0.9290\n",
            "Epoch 171/200\n",
            "41/41 [==============================] - 5s 130ms/step - loss: 0.3145 - accuracy: 0.9260\n",
            "Epoch 172/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.5437 - accuracy: 0.8847\n",
            "Epoch 173/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.2827 - accuracy: 0.9248\n",
            "Epoch 174/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4031 - accuracy: 0.9117\n",
            "Epoch 175/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3115 - accuracy: 0.9209\n",
            "Epoch 176/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3182 - accuracy: 0.9179\n",
            "Epoch 177/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.2955 - accuracy: 0.9244\n",
            "Epoch 178/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.3553 - accuracy: 0.9128\n",
            "Epoch 179/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.3992 - accuracy: 0.9213\n",
            "Epoch 180/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.8354 - accuracy: 0.8754\n",
            "Epoch 181/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.2961 - accuracy: 0.9298\n",
            "Epoch 182/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.2869 - accuracy: 0.9229\n",
            "Epoch 183/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3233 - accuracy: 0.9175\n",
            "Epoch 184/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3031 - accuracy: 0.9198\n",
            "Epoch 185/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3147 - accuracy: 0.9128\n",
            "Epoch 186/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3144 - accuracy: 0.9182\n",
            "Epoch 187/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.7041 - accuracy: 0.8978\n",
            "Epoch 188/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3973 - accuracy: 0.9074\n",
            "Epoch 189/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.5684 - accuracy: 0.8920\n",
            "Epoch 190/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.1819 - accuracy: 0.9437\n",
            "Epoch 191/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4454 - accuracy: 0.8955\n",
            "Epoch 192/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.4267 - accuracy: 0.9109\n",
            "Epoch 193/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.2290 - accuracy: 0.9341\n",
            "Epoch 194/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.3262 - accuracy: 0.9167\n",
            "Epoch 195/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.3914 - accuracy: 0.9148\n",
            "Epoch 196/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.2826 - accuracy: 0.9298\n",
            "Epoch 197/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.2957 - accuracy: 0.9364\n",
            "Epoch 198/200\n",
            "41/41 [==============================] - 5s 128ms/step - loss: 0.2484 - accuracy: 0.9302\n",
            "Epoch 199/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.6769 - accuracy: 0.9167\n",
            "Epoch 200/200\n",
            "41/41 [==============================] - 5s 129ms/step - loss: 0.4220 - accuracy: 0.8986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ2jTEeMsPVY",
        "outputId": "bdb8a4f4-a1e9-4076-d7ab-aa938c5399ac"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images,test_labels)\n",
        "print(\"Accuracy is :\", test_accuracy)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 3s 41ms/step - loss: 1.6096 - accuracy: 0.2192\n",
            "Accuracy is : 0.20693641901016235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfr4JH1SsWP2"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(1024, activation='tanh',input_shape=(150*150,)))\n",
        "model.add(layers.Dense(512, activation='tanh'))\n",
        "model.add(layers.Dense(256, activation='tanh'))\n",
        "model.add(layers.Dense(128, activation='tanh'))\n",
        "model.add(layers.Dense(64, activation='tanh'))\n",
        "model.add(layers.Dense(32, activation='tanh'))\n",
        "model.add(layers.Dense(16, activation='tanh'))\n",
        "model.add(layers.Dense(8, activation='tanh'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ4A73pfsao2",
        "outputId": "6eefe9dd-1b4f-44e3-aa7e-d7bba2780916"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=100, batch_size=128)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.0660 - accuracy: 0.9830\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.4951 - accuracy: 0.8866\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 0.9407 - accuracy: 0.8878\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.1198 - accuracy: 0.9699\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.2343 - accuracy: 0.9522\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.3502 - accuracy: 0.9356\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 0.3161 - accuracy: 0.9186\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.0718 - accuracy: 0.9803\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 0.9127 - accuracy: 0.8939\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 0.1026 - accuracy: 0.9718\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.7034 - accuracy: 0.8743\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.0703 - accuracy: 0.9776\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.7902 - accuracy: 0.8600\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0929 - accuracy: 0.9711\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.6032 - accuracy: 0.9047\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.1188 - accuracy: 0.9699\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2682 - accuracy: 0.9456\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.3653 - accuracy: 0.9024\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.2294 - accuracy: 0.9503\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.1320 - accuracy: 0.9672\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2646 - accuracy: 0.9391\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.3915 - accuracy: 0.9113\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2034 - accuracy: 0.9483\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.2156 - accuracy: 0.9456\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2420 - accuracy: 0.9310\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.5406 - accuracy: 0.9044\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.5265 - accuracy: 0.8951\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.3166 - accuracy: 0.9414\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.1250 - accuracy: 0.9622\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.5420 - accuracy: 0.8847\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.0828 - accuracy: 0.9745\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2504 - accuracy: 0.9503\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 1.0244 - accuracy: 0.8650\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0526 - accuracy: 0.9861\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 1.0997 - accuracy: 0.8731\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0841 - accuracy: 0.9780\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2594 - accuracy: 0.9437\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.3675 - accuracy: 0.9263\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.3695 - accuracy: 0.9410\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 0.2258 - accuracy: 0.9329\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.6233 - accuracy: 0.9013\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.0582 - accuracy: 0.9842\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.2531 - accuracy: 0.9329\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.5914 - accuracy: 0.8997\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.0901 - accuracy: 0.9780\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.1595 - accuracy: 0.9533\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 1.6191 - accuracy: 0.8450\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0724 - accuracy: 0.9796\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.1185 - accuracy: 0.9680\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.9387 - accuracy: 0.8855\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.1596 - accuracy: 0.9583\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.2070 - accuracy: 0.9491\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 0.3610 - accuracy: 0.9263\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.4400 - accuracy: 0.9067\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.0883 - accuracy: 0.9749\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.6784 - accuracy: 0.9020\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.4724 - accuracy: 0.9105\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.1366 - accuracy: 0.9680\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.2323 - accuracy: 0.9503\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.1373 - accuracy: 0.9626\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.4923 - accuracy: 0.9206\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.3153 - accuracy: 0.9244\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0818 - accuracy: 0.9780\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 1.3313 - accuracy: 0.8646\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0617 - accuracy: 0.9826\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2282 - accuracy: 0.9449\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.4527 - accuracy: 0.9044\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2890 - accuracy: 0.9348\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.1301 - accuracy: 0.9699\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.4768 - accuracy: 0.9071\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.3962 - accuracy: 0.9128\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.0619 - accuracy: 0.9830\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.2593 - accuracy: 0.9375\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.1148 - accuracy: 0.9676\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.5217 - accuracy: 0.9032\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.6160 - accuracy: 0.9128\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.0407 - accuracy: 0.9900\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.2084 - accuracy: 0.9510\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.5952 - accuracy: 0.8912\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.1547 - accuracy: 0.9637\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.4292 - accuracy: 0.9429\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.1386 - accuracy: 0.9583\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.1933 - accuracy: 0.9479\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.2819 - accuracy: 0.9364\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.4789 - accuracy: 0.9101\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.0627 - accuracy: 0.9842\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.5938 - accuracy: 0.9071\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0365 - accuracy: 0.9907\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 0.4256 - accuracy: 0.9267\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.0903 - accuracy: 0.9742\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.6312 - accuracy: 0.9105\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.1127 - accuracy: 0.9703\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.5252 - accuracy: 0.9024\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0419 - accuracy: 0.9896\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.2187 - accuracy: 0.9395\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.4742 - accuracy: 0.9182\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.1087 - accuracy: 0.9749\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.3855 - accuracy: 0.9348\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.6539 - accuracy: 0.9051\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0586 - accuracy: 0.9842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAMqlwj7tz9c",
        "outputId": "13bf6bbb-1535-4081-8a04-3eb46333218e"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images,test_labels)\n",
        "print(\"Now test accuracy is :\", test_accuracy)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 2s 40ms/step - loss: 1.6716 - accuracy: 0.2227\n",
            "Now test accuracy is : 0.22196531295776367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdn5rxNKt8gs"
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(1024, activation='relu',input_shape=(150*150,)))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPLA9VvYt_iq",
        "outputId": "94677533-c244-407a-8c2c-389dbf74cae3"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=100, batch_size=128)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.3703 - accuracy: 0.9229\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0899 - accuracy: 0.9761\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.5590 - accuracy: 0.9094\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.1542 - accuracy: 0.9680\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2755 - accuracy: 0.9341\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.6540 - accuracy: 0.9136\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.0466 - accuracy: 0.9877\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.1634 - accuracy: 0.9499\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.8164 - accuracy: 0.8878\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.2210 - accuracy: 0.9476\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.0464 - accuracy: 0.9873\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.3293 - accuracy: 0.9348\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.4398 - accuracy: 0.9233\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2019 - accuracy: 0.9637\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.5891 - accuracy: 0.8893\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.0341 - accuracy: 0.9911\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.1690 - accuracy: 0.9572\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 1.0164 - accuracy: 0.8808\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.1273 - accuracy: 0.9715\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 3s 167ms/step - loss: 0.2816 - accuracy: 0.9395\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.2147 - accuracy: 0.9429\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.0532 - accuracy: 0.9846\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 1.2549 - accuracy: 0.8735\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.0484 - accuracy: 0.9865\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.2153 - accuracy: 0.9452\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 3s 166ms/step - loss: 0.3137 - accuracy: 0.9333\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.3951 - accuracy: 0.9128\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.0859 - accuracy: 0.9753\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.4075 - accuracy: 0.9217\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 3s 166ms/step - loss: 0.2338 - accuracy: 0.9499\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.1229 - accuracy: 0.9668\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.3223 - accuracy: 0.9294\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.0688 - accuracy: 0.9799\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 3s 166ms/step - loss: 0.2887 - accuracy: 0.9464\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.1546 - accuracy: 0.9549\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2009 - accuracy: 0.9514\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.4125 - accuracy: 0.9306\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.4113 - accuracy: 0.9202\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.0323 - accuracy: 0.9915\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.3748 - accuracy: 0.9290\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.5252 - accuracy: 0.9136\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.0582 - accuracy: 0.9838\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.3270 - accuracy: 0.9240\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.1023 - accuracy: 0.9769\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.4699 - accuracy: 0.9159\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.3591 - accuracy: 0.9499\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.0749 - accuracy: 0.9865\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.5298 - accuracy: 0.9182\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.3804 - accuracy: 0.9317\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.0439 - accuracy: 0.9877\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.1721 - accuracy: 0.9537\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.4238 - accuracy: 0.9209\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.1733 - accuracy: 0.9583\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.6032 - accuracy: 0.9368\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.1754 - accuracy: 0.9630\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.0993 - accuracy: 0.9730\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.1848 - accuracy: 0.9491\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 0.3520 - accuracy: 0.9483\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 0.0656 - accuracy: 0.9826\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.6180 - accuracy: 0.9051\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.2061 - accuracy: 0.9518\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.7120 - accuracy: 0.9236\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0996 - accuracy: 0.9715\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.5036 - accuracy: 0.9256\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0491 - accuracy: 0.9842\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.2178 - accuracy: 0.9545\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.5924 - accuracy: 0.8982\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.0856 - accuracy: 0.9772\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.1215 - accuracy: 0.9734\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 1.0486 - accuracy: 0.8804\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.0393 - accuracy: 0.9892\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.2042 - accuracy: 0.9483\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 0.3232 - accuracy: 0.9344\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.5244 - accuracy: 0.9209\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0480 - accuracy: 0.9896\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2929 - accuracy: 0.9325\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.4831 - accuracy: 0.9233\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.0295 - accuracy: 0.9931\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.2591 - accuracy: 0.9383\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.8187 - accuracy: 0.9128\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0351 - accuracy: 0.9892\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.2162 - accuracy: 0.9560\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.0901 - accuracy: 0.9780\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.4424 - accuracy: 0.9329\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.4366 - accuracy: 0.9167\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.0331 - accuracy: 0.9927\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.1904 - accuracy: 0.9541\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.5790 - accuracy: 0.9186\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.2219 - accuracy: 0.9479\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.1692 - accuracy: 0.9672\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 1.1678 - accuracy: 0.8774\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.0333 - accuracy: 0.9915\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.6712 - accuracy: 0.9287\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.1519 - accuracy: 0.9645\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.1258 - accuracy: 0.9688\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.3701 - accuracy: 0.9406\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.4766 - accuracy: 0.9294\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.1867 - accuracy: 0.9711\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.1909 - accuracy: 0.9556\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.9591 - accuracy: 0.9005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TZs_rKuxElL",
        "outputId": "3f3a5785-a2d8-4e69-99c9-6f1ded25e142"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images,test_labels)\n",
        "print(\"Now Test accuracy is :\", test_accuracy)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 2s 40ms/step - loss: 1.7351 - accuracy: 0.1900\n",
            "Now Test accuracy is : 0.19190751016139984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1i3ZMv9xKxB"
      },
      "source": [
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(1024, activation='relu',input_shape=(150*150,)))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(32, activation='relu'))\n",
        "  model.add(layers.Dense(16, activation='relu'))\n",
        "  model.add(layers.Dense(8, activation='relu'))\n",
        "  model.add(layers.Dense(5, activation='softmax'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVowMIl9xNsq",
        "outputId": "8a60a32d-84ac-4a94-91c4-5dea3acb86e2"
      },
      "source": [
        "k=4\n",
        "num_val_samples = len(train_images) // k\n",
        "num_epochs = 200\n",
        "all_val_accuracy = []\n",
        "for i in range(k):\n",
        "  print(\"Processing Fold #\", i)\n",
        "  val_data = train_images[i * num_val_samples : (i+1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples : (i+1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_images[:i * num_val_samples], train_images[(i+1) * num_val_samples:]],axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples], train_labels[(i+1) * num_val_samples:]],axis=0)\n",
        "  model = build_model()\n",
        "  history = model.fit(partial_train_data, partial_train_targets, validation_data = (val_data,val_targets),epochs = num_epochs, batch_size = 128, verbose = 1)\n",
        "  val_acc_history = history.history['val_accuracy']\n",
        "  all_val_accuracy.append(val_acc_history)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Fold # 0\n",
            "Epoch 1/200\n",
            "16/16 [==============================] - 6s 312ms/step - loss: 2.4540 - accuracy: 0.2074 - val_loss: 1.6084 - val_accuracy: 0.2238\n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6080 - accuracy: 0.2285 - val_loss: 1.6077 - val_accuracy: 0.2238\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.6077 - accuracy: 0.2112 - val_loss: 1.6071 - val_accuracy: 0.2238\n",
            "Epoch 4/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6059 - accuracy: 0.2443 - val_loss: 1.6064 - val_accuracy: 0.2238\n",
            "Epoch 5/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6064 - accuracy: 0.2291 - val_loss: 1.6059 - val_accuracy: 0.2238\n",
            "Epoch 6/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6052 - accuracy: 0.2264 - val_loss: 1.6052 - val_accuracy: 0.2238\n",
            "Epoch 7/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.6040 - accuracy: 0.2373 - val_loss: 1.6047 - val_accuracy: 0.2238\n",
            "Epoch 8/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.6037 - accuracy: 0.2355 - val_loss: 1.6041 - val_accuracy: 0.2423\n",
            "Epoch 9/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6039 - accuracy: 0.2311 - val_loss: 1.6037 - val_accuracy: 0.2423\n",
            "Epoch 10/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6044 - accuracy: 0.2210 - val_loss: 1.6032 - val_accuracy: 0.2423\n",
            "Epoch 11/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6017 - accuracy: 0.2430 - val_loss: 1.6027 - val_accuracy: 0.2423\n",
            "Epoch 12/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6011 - accuracy: 0.2448 - val_loss: 1.6024 - val_accuracy: 0.2423\n",
            "Epoch 13/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6031 - accuracy: 0.2387 - val_loss: 1.6021 - val_accuracy: 0.2423\n",
            "Epoch 14/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.6004 - accuracy: 0.2381 - val_loss: 1.6018 - val_accuracy: 0.2423\n",
            "Epoch 15/200\n",
            "16/16 [==============================] - 5s 296ms/step - loss: 1.6008 - accuracy: 0.2358 - val_loss: 1.6015 - val_accuracy: 0.2423\n",
            "Epoch 16/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.6008 - accuracy: 0.2428 - val_loss: 1.6013 - val_accuracy: 0.2423\n",
            "Epoch 17/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5988 - accuracy: 0.2478 - val_loss: 1.6011 - val_accuracy: 0.2423\n",
            "Epoch 18/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6044 - accuracy: 0.2222 - val_loss: 1.6010 - val_accuracy: 0.2423\n",
            "Epoch 19/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5998 - accuracy: 0.2370 - val_loss: 1.6009 - val_accuracy: 0.2423\n",
            "Epoch 20/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6018 - accuracy: 0.2437 - val_loss: 1.6008 - val_accuracy: 0.2423\n",
            "Epoch 21/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6004 - accuracy: 0.2463 - val_loss: 1.6007 - val_accuracy: 0.2423\n",
            "Epoch 22/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5993 - accuracy: 0.2393 - val_loss: 1.6006 - val_accuracy: 0.2423\n",
            "Epoch 23/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5985 - accuracy: 0.2393 - val_loss: 1.6005 - val_accuracy: 0.2423\n",
            "Epoch 24/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6023 - accuracy: 0.2386 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 25/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.6005 - accuracy: 0.2487 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 26/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5978 - accuracy: 0.2365 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 27/200\n",
            "16/16 [==============================] - 5s 296ms/step - loss: 1.6013 - accuracy: 0.2421 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 28/200\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 1.5982 - accuracy: 0.2448 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 29/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5927 - accuracy: 0.2602 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 30/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5987 - accuracy: 0.2305 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 31/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.5993 - accuracy: 0.2503 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 32/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6001 - accuracy: 0.2391 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 33/200\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 1.5989 - accuracy: 0.2410 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 34/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5991 - accuracy: 0.2363 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 35/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6010 - accuracy: 0.2385 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 36/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6004 - accuracy: 0.2351 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 37/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5967 - accuracy: 0.2493 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 38/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6004 - accuracy: 0.2350 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 39/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6002 - accuracy: 0.2371 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 40/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5989 - accuracy: 0.2419 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 41/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5997 - accuracy: 0.2320 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 42/200\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 1.6007 - accuracy: 0.2362 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 43/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5960 - accuracy: 0.2361 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 44/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5979 - accuracy: 0.2384 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 45/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.5982 - accuracy: 0.2406 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 46/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5956 - accuracy: 0.2533 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 47/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5945 - accuracy: 0.2425 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 48/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5982 - accuracy: 0.2543 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 49/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5977 - accuracy: 0.2321 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 50/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5967 - accuracy: 0.2471 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 51/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.6017 - accuracy: 0.2391 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 52/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5974 - accuracy: 0.2454 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 53/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5991 - accuracy: 0.2410 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 54/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5952 - accuracy: 0.2454 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 55/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6000 - accuracy: 0.2456 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 56/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5978 - accuracy: 0.2460 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 57/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.6003 - accuracy: 0.2400 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 58/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5928 - accuracy: 0.2474 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 59/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5960 - accuracy: 0.2415 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 60/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.6027 - accuracy: 0.2277 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 61/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5938 - accuracy: 0.2480 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 62/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5976 - accuracy: 0.2409 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 63/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5953 - accuracy: 0.2420 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 64/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5982 - accuracy: 0.2351 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 65/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6002 - accuracy: 0.2377 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 66/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5979 - accuracy: 0.2355 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 67/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6015 - accuracy: 0.2438 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 68/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6004 - accuracy: 0.2338 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 69/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5931 - accuracy: 0.2607 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 70/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6020 - accuracy: 0.2270 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 71/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6003 - accuracy: 0.2387 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 72/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5933 - accuracy: 0.2567 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 73/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5975 - accuracy: 0.2384 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 74/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5997 - accuracy: 0.2360 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 75/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5917 - accuracy: 0.2508 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 76/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5928 - accuracy: 0.2497 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 77/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5974 - accuracy: 0.2431 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 78/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.6015 - accuracy: 0.2309 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 79/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.5990 - accuracy: 0.2434 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 80/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5927 - accuracy: 0.2638 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 81/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5958 - accuracy: 0.2413 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 82/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6000 - accuracy: 0.2406 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 83/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5974 - accuracy: 0.2347 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 84/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5981 - accuracy: 0.2367 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 85/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.5974 - accuracy: 0.2350 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 86/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6012 - accuracy: 0.2305 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 87/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5974 - accuracy: 0.2431 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 88/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5926 - accuracy: 0.2485 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 89/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5963 - accuracy: 0.2428 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 90/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6015 - accuracy: 0.2348 - val_loss: 1.6002 - val_accuracy: 0.2423\n",
            "Epoch 91/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5997 - accuracy: 0.2371 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 92/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6009 - accuracy: 0.2307 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 93/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5979 - accuracy: 0.2444 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 94/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5943 - accuracy: 0.2410 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 95/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5997 - accuracy: 0.2439 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 96/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5967 - accuracy: 0.2504 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 97/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5974 - accuracy: 0.2409 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 98/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5986 - accuracy: 0.2404 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 99/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5971 - accuracy: 0.2414 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 100/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5986 - accuracy: 0.2303 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 101/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5951 - accuracy: 0.2447 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 102/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5941 - accuracy: 0.2599 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 103/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5993 - accuracy: 0.2369 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 104/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5963 - accuracy: 0.2513 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 105/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5987 - accuracy: 0.2433 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 106/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5946 - accuracy: 0.2430 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 107/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.6003 - accuracy: 0.2331 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 108/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5938 - accuracy: 0.2592 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 109/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6027 - accuracy: 0.2303 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 110/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5968 - accuracy: 0.2398 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 111/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5949 - accuracy: 0.2532 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 112/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5982 - accuracy: 0.2485 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 113/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5923 - accuracy: 0.2491 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 114/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5989 - accuracy: 0.2530 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 115/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5999 - accuracy: 0.2341 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 116/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5975 - accuracy: 0.2343 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 117/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5970 - accuracy: 0.2438 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 118/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5967 - accuracy: 0.2457 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 119/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5974 - accuracy: 0.2486 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 120/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5971 - accuracy: 0.2406 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 121/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5960 - accuracy: 0.2569 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 122/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5959 - accuracy: 0.2507 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 123/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5998 - accuracy: 0.2361 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 124/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6002 - accuracy: 0.2345 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 125/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6011 - accuracy: 0.2272 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 126/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5968 - accuracy: 0.2514 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 127/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5989 - accuracy: 0.2314 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 128/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6002 - accuracy: 0.2486 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 129/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5986 - accuracy: 0.2481 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 130/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5960 - accuracy: 0.2511 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 131/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5972 - accuracy: 0.2475 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 132/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5999 - accuracy: 0.2451 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 133/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6011 - accuracy: 0.2378 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 134/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5958 - accuracy: 0.2450 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 135/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5998 - accuracy: 0.2319 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 136/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6019 - accuracy: 0.2345 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 137/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6011 - accuracy: 0.2294 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 138/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5976 - accuracy: 0.2474 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 139/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5975 - accuracy: 0.2387 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 140/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5972 - accuracy: 0.2343 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 141/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6004 - accuracy: 0.2409 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 142/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6017 - accuracy: 0.2278 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 143/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5993 - accuracy: 0.2293 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 144/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6006 - accuracy: 0.2350 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 145/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.5977 - accuracy: 0.2359 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 146/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.5994 - accuracy: 0.2363 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 147/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.6023 - accuracy: 0.2307 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 148/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6019 - accuracy: 0.2303 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 149/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5958 - accuracy: 0.2521 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 150/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5993 - accuracy: 0.2488 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 151/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5972 - accuracy: 0.2362 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 152/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5989 - accuracy: 0.2386 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 153/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6008 - accuracy: 0.2313 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 154/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5967 - accuracy: 0.2406 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 155/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5985 - accuracy: 0.2418 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 156/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5930 - accuracy: 0.2418 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 157/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5987 - accuracy: 0.2393 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 158/200\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 1.5985 - accuracy: 0.2432 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 159/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.6005 - accuracy: 0.2396 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 160/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.6027 - accuracy: 0.2397 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 161/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.6012 - accuracy: 0.2306 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 162/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5968 - accuracy: 0.2423 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 163/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5920 - accuracy: 0.2580 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 164/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5948 - accuracy: 0.2507 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 165/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5986 - accuracy: 0.2352 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 166/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5987 - accuracy: 0.2472 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 167/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5964 - accuracy: 0.2395 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 168/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5933 - accuracy: 0.2579 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 169/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5998 - accuracy: 0.2313 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 170/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.6014 - accuracy: 0.2387 - val_loss: 1.6003 - val_accuracy: 0.2423\n",
            "Epoch 171/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.6008 - accuracy: 0.2357 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 172/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5993 - accuracy: 0.2377 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 173/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5985 - accuracy: 0.2347 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 174/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.6008 - accuracy: 0.2398 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 175/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5965 - accuracy: 0.2501 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 176/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5942 - accuracy: 0.2562 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 177/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5978 - accuracy: 0.2446 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 178/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5955 - accuracy: 0.2389 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 179/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5931 - accuracy: 0.2585 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 180/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5961 - accuracy: 0.2516 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 181/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5956 - accuracy: 0.2461 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 182/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.6006 - accuracy: 0.2371 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 183/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5990 - accuracy: 0.2372 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 184/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5997 - accuracy: 0.2394 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 185/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5955 - accuracy: 0.2410 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 186/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5922 - accuracy: 0.2580 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 187/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5958 - accuracy: 0.2471 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 188/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5962 - accuracy: 0.2551 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 189/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5967 - accuracy: 0.2451 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 190/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6006 - accuracy: 0.2383 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 191/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5966 - accuracy: 0.2437 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 192/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5957 - accuracy: 0.2504 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 193/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6009 - accuracy: 0.2356 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 194/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5986 - accuracy: 0.2333 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 195/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5989 - accuracy: 0.2509 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 196/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5972 - accuracy: 0.2425 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 197/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5966 - accuracy: 0.2423 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 198/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6000 - accuracy: 0.2481 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 199/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5948 - accuracy: 0.2544 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Epoch 200/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5927 - accuracy: 0.2616 - val_loss: 1.6004 - val_accuracy: 0.2423\n",
            "Processing Fold # 1\n",
            "Epoch 1/200\n",
            "16/16 [==============================] - 6s 319ms/step - loss: 2.1508 - accuracy: 0.1822 - val_loss: 1.6089 - val_accuracy: 0.2392\n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.6102 - accuracy: 0.2223 - val_loss: 1.6076 - val_accuracy: 0.2469\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6084 - accuracy: 0.2299 - val_loss: 1.6075 - val_accuracy: 0.2377\n",
            "Epoch 4/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.6072 - accuracy: 0.2457 - val_loss: 1.6067 - val_accuracy: 0.2377\n",
            "Epoch 5/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.6064 - accuracy: 0.2429 - val_loss: 1.6060 - val_accuracy: 0.2377\n",
            "Epoch 6/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.6063 - accuracy: 0.2417 - val_loss: 1.6053 - val_accuracy: 0.2377\n",
            "Epoch 7/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6056 - accuracy: 0.2370 - val_loss: 1.6046 - val_accuracy: 0.2377\n",
            "Epoch 8/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.6054 - accuracy: 0.2400 - val_loss: 1.6040 - val_accuracy: 0.2377\n",
            "Epoch 9/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.6043 - accuracy: 0.2404 - val_loss: 1.6032 - val_accuracy: 0.2377\n",
            "Epoch 10/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6043 - accuracy: 0.2274 - val_loss: 1.6027 - val_accuracy: 0.2377\n",
            "Epoch 11/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6030 - accuracy: 0.2452 - val_loss: 1.6022 - val_accuracy: 0.2377\n",
            "Epoch 12/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.6023 - accuracy: 0.2437 - val_loss: 1.6018 - val_accuracy: 0.2377\n",
            "Epoch 13/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.6014 - accuracy: 0.2434 - val_loss: 1.6014 - val_accuracy: 0.2377\n",
            "Epoch 14/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.6020 - accuracy: 0.2353 - val_loss: 1.6010 - val_accuracy: 0.2377\n",
            "Epoch 15/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.6025 - accuracy: 0.2290 - val_loss: 1.6007 - val_accuracy: 0.2377\n",
            "Epoch 16/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5992 - accuracy: 0.2456 - val_loss: 1.6004 - val_accuracy: 0.2377\n",
            "Epoch 17/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5997 - accuracy: 0.2415 - val_loss: 1.6002 - val_accuracy: 0.2377\n",
            "Epoch 18/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5991 - accuracy: 0.2431 - val_loss: 1.5999 - val_accuracy: 0.2377\n",
            "Epoch 19/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6037 - accuracy: 0.2199 - val_loss: 1.5998 - val_accuracy: 0.2377\n",
            "Epoch 20/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5976 - accuracy: 0.2543 - val_loss: 1.5995 - val_accuracy: 0.2377\n",
            "Epoch 21/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5990 - accuracy: 0.2439 - val_loss: 1.5994 - val_accuracy: 0.2377\n",
            "Epoch 22/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6018 - accuracy: 0.2282 - val_loss: 1.5993 - val_accuracy: 0.2377\n",
            "Epoch 23/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6015 - accuracy: 0.2412 - val_loss: 1.5991 - val_accuracy: 0.2377\n",
            "Epoch 24/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6017 - accuracy: 0.2313 - val_loss: 1.5990 - val_accuracy: 0.2377\n",
            "Epoch 25/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6043 - accuracy: 0.2394 - val_loss: 1.5989 - val_accuracy: 0.2377\n",
            "Epoch 26/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6010 - accuracy: 0.2453 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 27/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5987 - accuracy: 0.2445 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 28/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5995 - accuracy: 0.2358 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 29/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6013 - accuracy: 0.2460 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 30/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6001 - accuracy: 0.2414 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 31/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6007 - accuracy: 0.2341 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 32/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5973 - accuracy: 0.2564 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 33/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5959 - accuracy: 0.2592 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 34/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6010 - accuracy: 0.2381 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 35/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5979 - accuracy: 0.2351 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 36/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5991 - accuracy: 0.2438 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 37/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6021 - accuracy: 0.2220 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 38/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6022 - accuracy: 0.2447 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 39/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6016 - accuracy: 0.2322 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 40/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5993 - accuracy: 0.2393 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 41/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5987 - accuracy: 0.2498 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 42/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6031 - accuracy: 0.2322 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 43/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6014 - accuracy: 0.2343 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 44/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5987 - accuracy: 0.2435 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 45/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5969 - accuracy: 0.2466 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 46/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5999 - accuracy: 0.2469 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 47/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5982 - accuracy: 0.2522 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 48/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5992 - accuracy: 0.2402 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 49/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5996 - accuracy: 0.2323 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 50/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5959 - accuracy: 0.2422 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 51/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6028 - accuracy: 0.2292 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 52/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5978 - accuracy: 0.2396 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 53/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6001 - accuracy: 0.2446 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 54/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5965 - accuracy: 0.2474 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 55/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.6014 - accuracy: 0.2392 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 56/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5989 - accuracy: 0.2448 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 57/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6041 - accuracy: 0.2269 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 58/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6017 - accuracy: 0.2266 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 59/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5991 - accuracy: 0.2341 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 60/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5967 - accuracy: 0.2400 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 61/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5997 - accuracy: 0.2382 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 62/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6011 - accuracy: 0.2364 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 63/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5980 - accuracy: 0.2435 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 64/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5990 - accuracy: 0.2376 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 65/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5975 - accuracy: 0.2393 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 66/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5997 - accuracy: 0.2394 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 67/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5977 - accuracy: 0.2499 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 68/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5984 - accuracy: 0.2527 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 69/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5969 - accuracy: 0.2468 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 70/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.6009 - accuracy: 0.2332 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 71/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.6010 - accuracy: 0.2441 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 72/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5989 - accuracy: 0.2460 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 73/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5972 - accuracy: 0.2480 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 74/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5983 - accuracy: 0.2456 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 75/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6017 - accuracy: 0.2326 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 76/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5970 - accuracy: 0.2464 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 77/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5962 - accuracy: 0.2540 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 78/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5988 - accuracy: 0.2448 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 79/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5927 - accuracy: 0.2659 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 80/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.6039 - accuracy: 0.2308 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 81/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6000 - accuracy: 0.2456 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 82/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5999 - accuracy: 0.2484 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 83/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.6010 - accuracy: 0.2329 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 84/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.6001 - accuracy: 0.2436 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 85/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6001 - accuracy: 0.2306 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 86/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5997 - accuracy: 0.2419 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 87/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.6031 - accuracy: 0.2224 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 88/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5960 - accuracy: 0.2409 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 89/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5964 - accuracy: 0.2428 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 90/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.6017 - accuracy: 0.2352 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 91/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5993 - accuracy: 0.2428 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 92/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6045 - accuracy: 0.2285 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 93/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5961 - accuracy: 0.2437 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 94/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5944 - accuracy: 0.2542 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 95/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6004 - accuracy: 0.2350 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 96/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5927 - accuracy: 0.2603 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 97/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5991 - accuracy: 0.2471 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 98/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6016 - accuracy: 0.2354 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 99/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5983 - accuracy: 0.2440 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 100/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5978 - accuracy: 0.2467 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 101/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5979 - accuracy: 0.2350 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 102/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5981 - accuracy: 0.2459 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 103/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5961 - accuracy: 0.2484 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 104/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5960 - accuracy: 0.2436 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 105/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.5963 - accuracy: 0.2482 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 106/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.5984 - accuracy: 0.2388 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 107/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5947 - accuracy: 0.2476 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 108/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5992 - accuracy: 0.2354 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 109/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5981 - accuracy: 0.2388 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 110/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5976 - accuracy: 0.2449 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 111/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5926 - accuracy: 0.2572 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 112/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5983 - accuracy: 0.2444 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 113/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5993 - accuracy: 0.2436 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 114/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6033 - accuracy: 0.2425 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 115/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5986 - accuracy: 0.2461 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 116/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5976 - accuracy: 0.2481 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 117/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5994 - accuracy: 0.2357 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 118/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5980 - accuracy: 0.2465 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 119/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.6050 - accuracy: 0.2347 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 120/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.6032 - accuracy: 0.2362 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 121/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5976 - accuracy: 0.2289 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 122/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5937 - accuracy: 0.2547 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 123/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6039 - accuracy: 0.2270 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 124/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5955 - accuracy: 0.2489 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 125/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5974 - accuracy: 0.2425 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 126/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6019 - accuracy: 0.2398 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 127/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.6021 - accuracy: 0.2391 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 128/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5962 - accuracy: 0.2426 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 129/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5955 - accuracy: 0.2517 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 130/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6005 - accuracy: 0.2423 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 131/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.6023 - accuracy: 0.2340 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 132/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5958 - accuracy: 0.2486 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 133/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5999 - accuracy: 0.2421 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 134/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.6007 - accuracy: 0.2434 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 135/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6008 - accuracy: 0.2327 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 136/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5957 - accuracy: 0.2531 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 137/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5948 - accuracy: 0.2477 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 138/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5964 - accuracy: 0.2667 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 139/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5974 - accuracy: 0.2375 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 140/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.5994 - accuracy: 0.2421 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 141/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5963 - accuracy: 0.2503 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 142/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6023 - accuracy: 0.2336 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 143/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6019 - accuracy: 0.2411 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 144/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5968 - accuracy: 0.2452 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 145/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5950 - accuracy: 0.2529 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 146/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5937 - accuracy: 0.2421 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 147/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5972 - accuracy: 0.2386 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 148/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6020 - accuracy: 0.2388 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 149/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5962 - accuracy: 0.2439 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 150/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5979 - accuracy: 0.2476 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 151/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5964 - accuracy: 0.2526 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 152/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6033 - accuracy: 0.2397 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 153/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5961 - accuracy: 0.2519 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 154/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5968 - accuracy: 0.2391 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 155/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5953 - accuracy: 0.2403 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 156/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6021 - accuracy: 0.2451 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 157/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5994 - accuracy: 0.2429 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 158/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.5999 - accuracy: 0.2398 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 159/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.6010 - accuracy: 0.2425 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 160/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5969 - accuracy: 0.2507 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 161/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5948 - accuracy: 0.2487 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 162/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5991 - accuracy: 0.2341 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 163/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6006 - accuracy: 0.2400 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 164/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5912 - accuracy: 0.2606 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 165/200\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 1.5995 - accuracy: 0.2333 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 166/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5982 - accuracy: 0.2491 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 167/200\n",
            "16/16 [==============================] - 5s 297ms/step - loss: 1.6021 - accuracy: 0.2373 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 168/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.6009 - accuracy: 0.2460 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 169/200\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 1.5982 - accuracy: 0.2448 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 170/200\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 1.5960 - accuracy: 0.2550 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 171/200\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 1.5963 - accuracy: 0.2487 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 172/200\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.5940 - accuracy: 0.2606 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 173/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5972 - accuracy: 0.2395 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 174/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5957 - accuracy: 0.2443 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 175/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5975 - accuracy: 0.2451 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 176/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5943 - accuracy: 0.2481 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 177/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6000 - accuracy: 0.2367 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 178/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.6019 - accuracy: 0.2300 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 179/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5966 - accuracy: 0.2374 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 180/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5948 - accuracy: 0.2599 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 181/200\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.5981 - accuracy: 0.2388 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 182/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.5978 - accuracy: 0.2344 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 183/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5979 - accuracy: 0.2452 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 184/200\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.5991 - accuracy: 0.2371 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 185/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5976 - accuracy: 0.2474 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 186/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6009 - accuracy: 0.2421 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 187/200\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.6009 - accuracy: 0.2336 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 188/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5971 - accuracy: 0.2356 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 189/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5996 - accuracy: 0.2371 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 190/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.6002 - accuracy: 0.2364 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 191/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5995 - accuracy: 0.2453 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 192/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5975 - accuracy: 0.2420 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 193/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5978 - accuracy: 0.2417 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 194/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5955 - accuracy: 0.2502 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 195/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5985 - accuracy: 0.2421 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 196/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5960 - accuracy: 0.2477 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 197/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.6001 - accuracy: 0.2457 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 198/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5997 - accuracy: 0.2417 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 199/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.6004 - accuracy: 0.2428 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 200/200\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 1.5973 - accuracy: 0.2418 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Processing Fold # 2\n",
            "Epoch 1/200\n",
            "16/16 [==============================] - 6s 319ms/step - loss: 2.3230 - accuracy: 0.2056 - val_loss: 1.7176 - val_accuracy: 0.2500\n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.7857 - accuracy: 0.2195 - val_loss: 1.6464 - val_accuracy: 0.2500\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.6540 - accuracy: 0.2019 - val_loss: 1.5940 - val_accuracy: 0.2577\n",
            "Epoch 4/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.6423 - accuracy: 0.2311 - val_loss: 1.6128 - val_accuracy: 0.2515\n",
            "Epoch 5/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.6138 - accuracy: 0.2321 - val_loss: 1.6052 - val_accuracy: 0.2577\n",
            "Epoch 6/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.6337 - accuracy: 0.2347 - val_loss: 1.5950 - val_accuracy: 0.2577\n",
            "Epoch 7/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.6112 - accuracy: 0.2373 - val_loss: 1.5969 - val_accuracy: 0.2562\n",
            "Epoch 8/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.6123 - accuracy: 0.2139 - val_loss: 1.6273 - val_accuracy: 0.1543\n",
            "Epoch 9/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.6206 - accuracy: 0.2185 - val_loss: 1.5925 - val_accuracy: 0.2577\n",
            "Epoch 10/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.6063 - accuracy: 0.2246 - val_loss: 1.5964 - val_accuracy: 0.2593\n",
            "Epoch 11/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.6006 - accuracy: 0.2452 - val_loss: 1.5921 - val_accuracy: 0.2577\n",
            "Epoch 12/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.6097 - accuracy: 0.2342 - val_loss: 1.5905 - val_accuracy: 0.2577\n",
            "Epoch 13/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.6018 - accuracy: 0.2240 - val_loss: 1.5891 - val_accuracy: 0.2577\n",
            "Epoch 14/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5973 - accuracy: 0.2446 - val_loss: 1.5901 - val_accuracy: 0.2593\n",
            "Epoch 15/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5986 - accuracy: 0.2407 - val_loss: 1.5902 - val_accuracy: 0.2500\n",
            "Epoch 16/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.6038 - accuracy: 0.2316 - val_loss: 1.5931 - val_accuracy: 0.2377\n",
            "Epoch 17/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5956 - accuracy: 0.2357 - val_loss: 1.5941 - val_accuracy: 0.2330\n",
            "Epoch 18/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5902 - accuracy: 0.2491 - val_loss: 1.5913 - val_accuracy: 0.2454\n",
            "Epoch 19/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5951 - accuracy: 0.2506 - val_loss: 1.5850 - val_accuracy: 0.2654\n",
            "Epoch 20/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5932 - accuracy: 0.2544 - val_loss: 1.6047 - val_accuracy: 0.2608\n",
            "Epoch 21/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.6058 - accuracy: 0.2424 - val_loss: 1.5909 - val_accuracy: 0.2469\n",
            "Epoch 22/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5994 - accuracy: 0.2393 - val_loss: 1.5917 - val_accuracy: 0.2469\n",
            "Epoch 23/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5893 - accuracy: 0.2595 - val_loss: 1.5826 - val_accuracy: 0.2685\n",
            "Epoch 24/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5938 - accuracy: 0.2512 - val_loss: 1.5874 - val_accuracy: 0.2515\n",
            "Epoch 25/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5810 - accuracy: 0.2756 - val_loss: 1.5815 - val_accuracy: 0.2701\n",
            "Epoch 26/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5907 - accuracy: 0.2564 - val_loss: 1.5848 - val_accuracy: 0.2716\n",
            "Epoch 27/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5823 - accuracy: 0.2555 - val_loss: 1.5850 - val_accuracy: 0.2593\n",
            "Epoch 28/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5696 - accuracy: 0.2942 - val_loss: 1.5845 - val_accuracy: 0.2546\n",
            "Epoch 29/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5707 - accuracy: 0.2779 - val_loss: 1.6210 - val_accuracy: 0.2531\n",
            "Epoch 30/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.6268 - accuracy: 0.2417 - val_loss: 1.5876 - val_accuracy: 0.2577\n",
            "Epoch 31/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5977 - accuracy: 0.2415 - val_loss: 1.6421 - val_accuracy: 0.2562\n",
            "Epoch 32/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5996 - accuracy: 0.2736 - val_loss: 1.6036 - val_accuracy: 0.2176\n",
            "Epoch 33/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5679 - accuracy: 0.2977 - val_loss: 1.5811 - val_accuracy: 0.2608\n",
            "Epoch 34/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5637 - accuracy: 0.3025 - val_loss: 1.5878 - val_accuracy: 0.2577\n",
            "Epoch 35/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5869 - accuracy: 0.2681 - val_loss: 1.5839 - val_accuracy: 0.2593\n",
            "Epoch 36/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5594 - accuracy: 0.2873 - val_loss: 1.5892 - val_accuracy: 0.2685\n",
            "Epoch 37/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5698 - accuracy: 0.2830 - val_loss: 1.5923 - val_accuracy: 0.2608\n",
            "Epoch 38/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5566 - accuracy: 0.2874 - val_loss: 1.5808 - val_accuracy: 0.2670\n",
            "Epoch 39/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5325 - accuracy: 0.3169 - val_loss: 1.6653 - val_accuracy: 0.2515\n",
            "Epoch 40/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5963 - accuracy: 0.2579 - val_loss: 1.6206 - val_accuracy: 0.2145\n",
            "Epoch 41/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5604 - accuracy: 0.2848 - val_loss: 1.6100 - val_accuracy: 0.2130\n",
            "Epoch 42/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5364 - accuracy: 0.3043 - val_loss: 1.5940 - val_accuracy: 0.2438\n",
            "Epoch 43/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5676 - accuracy: 0.2832 - val_loss: 1.6053 - val_accuracy: 0.2315\n",
            "Epoch 44/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5413 - accuracy: 0.3128 - val_loss: 1.6065 - val_accuracy: 0.2901\n",
            "Epoch 45/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5114 - accuracy: 0.3216 - val_loss: 1.6436 - val_accuracy: 0.2438\n",
            "Epoch 46/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.6258 - accuracy: 0.2658 - val_loss: 1.5780 - val_accuracy: 0.2654\n",
            "Epoch 47/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5380 - accuracy: 0.3018 - val_loss: 1.8536 - val_accuracy: 0.2500\n",
            "Epoch 48/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.6242 - accuracy: 0.2713 - val_loss: 1.6002 - val_accuracy: 0.2593\n",
            "Epoch 49/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5094 - accuracy: 0.3173 - val_loss: 1.5881 - val_accuracy: 0.2901\n",
            "Epoch 50/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5350 - accuracy: 0.3148 - val_loss: 1.5722 - val_accuracy: 0.2639\n",
            "Epoch 51/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.4931 - accuracy: 0.3248 - val_loss: 1.6115 - val_accuracy: 0.2639\n",
            "Epoch 52/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5191 - accuracy: 0.3127 - val_loss: 1.5872 - val_accuracy: 0.2840\n",
            "Epoch 53/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.4478 - accuracy: 0.3489 - val_loss: 1.6475 - val_accuracy: 0.2485\n",
            "Epoch 54/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.6676 - accuracy: 0.2359 - val_loss: 1.6827 - val_accuracy: 0.2500\n",
            "Epoch 55/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5198 - accuracy: 0.3082 - val_loss: 1.5701 - val_accuracy: 0.2747\n",
            "Epoch 56/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.4820 - accuracy: 0.3187 - val_loss: 1.6068 - val_accuracy: 0.2685\n",
            "Epoch 57/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.5119 - accuracy: 0.3191 - val_loss: 1.5724 - val_accuracy: 0.2701\n",
            "Epoch 58/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5158 - accuracy: 0.3081 - val_loss: 1.6290 - val_accuracy: 0.2577\n",
            "Epoch 59/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.4744 - accuracy: 0.3500 - val_loss: 1.5948 - val_accuracy: 0.2840\n",
            "Epoch 60/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.4289 - accuracy: 0.3678 - val_loss: 1.6031 - val_accuracy: 0.2932\n",
            "Epoch 61/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.4206 - accuracy: 0.3409 - val_loss: 1.5903 - val_accuracy: 0.2809\n",
            "Epoch 62/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.4219 - accuracy: 0.3590 - val_loss: 1.6357 - val_accuracy: 0.2901\n",
            "Epoch 63/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.4561 - accuracy: 0.3342 - val_loss: 1.5751 - val_accuracy: 0.2824\n",
            "Epoch 64/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.4115 - accuracy: 0.3616 - val_loss: 1.6530 - val_accuracy: 0.2901\n",
            "Epoch 65/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.3609 - accuracy: 0.3968 - val_loss: 1.6708 - val_accuracy: 0.2948\n",
            "Epoch 66/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.3591 - accuracy: 0.3898 - val_loss: 1.6233 - val_accuracy: 0.2932\n",
            "Epoch 67/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.3446 - accuracy: 0.3975 - val_loss: 1.6910 - val_accuracy: 0.2870\n",
            "Epoch 68/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.4768 - accuracy: 0.3318 - val_loss: 1.5746 - val_accuracy: 0.2716\n",
            "Epoch 69/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.4582 - accuracy: 0.3343 - val_loss: 1.7324 - val_accuracy: 0.2485\n",
            "Epoch 70/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.4078 - accuracy: 0.3630 - val_loss: 1.6307 - val_accuracy: 0.2948\n",
            "Epoch 71/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.4427 - accuracy: 0.3598 - val_loss: 1.6842 - val_accuracy: 0.2531\n",
            "Epoch 72/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.3484 - accuracy: 0.4032 - val_loss: 1.6645 - val_accuracy: 0.3040\n",
            "Epoch 73/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.4784 - accuracy: 0.3355 - val_loss: 1.7770 - val_accuracy: 0.2469\n",
            "Epoch 74/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.4048 - accuracy: 0.3732 - val_loss: 2.1363 - val_accuracy: 0.2068\n",
            "Epoch 75/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5426 - accuracy: 0.3450 - val_loss: 1.5718 - val_accuracy: 0.2623\n",
            "Epoch 76/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.3883 - accuracy: 0.3730 - val_loss: 1.7675 - val_accuracy: 0.2762\n",
            "Epoch 77/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.3294 - accuracy: 0.3959 - val_loss: 1.8776 - val_accuracy: 0.2500\n",
            "Epoch 78/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.3727 - accuracy: 0.3715 - val_loss: 1.7112 - val_accuracy: 0.2932\n",
            "Epoch 79/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.4385 - accuracy: 0.3535 - val_loss: 1.6254 - val_accuracy: 0.2454\n",
            "Epoch 80/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.3402 - accuracy: 0.3987 - val_loss: 2.2056 - val_accuracy: 0.2299\n",
            "Epoch 81/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.3890 - accuracy: 0.3773 - val_loss: 1.8095 - val_accuracy: 0.2701\n",
            "Epoch 82/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.3399 - accuracy: 0.3925 - val_loss: 1.9968 - val_accuracy: 0.2377\n",
            "Epoch 83/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.3583 - accuracy: 0.3904 - val_loss: 1.6516 - val_accuracy: 0.2932\n",
            "Epoch 84/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.3331 - accuracy: 0.3912 - val_loss: 1.6954 - val_accuracy: 0.3102\n",
            "Epoch 85/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.2982 - accuracy: 0.4065 - val_loss: 1.9370 - val_accuracy: 0.2932\n",
            "Epoch 86/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.2667 - accuracy: 0.4379 - val_loss: 1.7496 - val_accuracy: 0.2978\n",
            "Epoch 87/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.3187 - accuracy: 0.3861 - val_loss: 1.7044 - val_accuracy: 0.3210\n",
            "Epoch 88/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.3834 - accuracy: 0.3709 - val_loss: 1.6197 - val_accuracy: 0.2639\n",
            "Epoch 89/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.3516 - accuracy: 0.3944 - val_loss: 1.6493 - val_accuracy: 0.2870\n",
            "Epoch 90/200\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.2634 - accuracy: 0.4292 - val_loss: 1.8835 - val_accuracy: 0.2855\n",
            "Epoch 91/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.2497 - accuracy: 0.4546 - val_loss: 1.7703 - val_accuracy: 0.3056\n",
            "Epoch 92/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.3339 - accuracy: 0.4250 - val_loss: 2.3571 - val_accuracy: 0.2531\n",
            "Epoch 93/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.3552 - accuracy: 0.3707 - val_loss: 2.0100 - val_accuracy: 0.2593\n",
            "Epoch 94/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.2472 - accuracy: 0.4229 - val_loss: 1.7385 - val_accuracy: 0.3040\n",
            "Epoch 95/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.2294 - accuracy: 0.4491 - val_loss: 1.9136 - val_accuracy: 0.2948\n",
            "Epoch 96/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.3031 - accuracy: 0.4230 - val_loss: 2.0013 - val_accuracy: 0.2423\n",
            "Epoch 97/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.3062 - accuracy: 0.3996 - val_loss: 1.9267 - val_accuracy: 0.2701\n",
            "Epoch 98/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.3129 - accuracy: 0.4018 - val_loss: 1.7737 - val_accuracy: 0.2963\n",
            "Epoch 99/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.2695 - accuracy: 0.4288 - val_loss: 1.8695 - val_accuracy: 0.2824\n",
            "Epoch 100/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.2182 - accuracy: 0.4620 - val_loss: 2.4075 - val_accuracy: 0.2654\n",
            "Epoch 101/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.2384 - accuracy: 0.4477 - val_loss: 3.0745 - val_accuracy: 0.2515\n",
            "Epoch 102/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.3807 - accuracy: 0.3878 - val_loss: 2.2908 - val_accuracy: 0.2006\n",
            "Epoch 103/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.3629 - accuracy: 0.3704 - val_loss: 1.7292 - val_accuracy: 0.3025\n",
            "Epoch 104/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.3156 - accuracy: 0.4346 - val_loss: 1.6511 - val_accuracy: 0.2901\n",
            "Epoch 105/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.2725 - accuracy: 0.4396 - val_loss: 1.7093 - val_accuracy: 0.3071\n",
            "Epoch 106/200\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.2113 - accuracy: 0.4605 - val_loss: 1.8403 - val_accuracy: 0.3117\n",
            "Epoch 107/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.4497 - accuracy: 0.3678 - val_loss: 1.7365 - val_accuracy: 0.2546\n",
            "Epoch 108/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.3021 - accuracy: 0.3952 - val_loss: 2.0333 - val_accuracy: 0.2840\n",
            "Epoch 109/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.2682 - accuracy: 0.4144 - val_loss: 1.8655 - val_accuracy: 0.2994\n",
            "Epoch 110/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.2551 - accuracy: 0.4331 - val_loss: 2.3644 - val_accuracy: 0.2593\n",
            "Epoch 111/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.2126 - accuracy: 0.4378 - val_loss: 1.8720 - val_accuracy: 0.3086\n",
            "Epoch 112/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.3071 - accuracy: 0.4088 - val_loss: 1.7871 - val_accuracy: 0.3148\n",
            "Epoch 113/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.2701 - accuracy: 0.4254 - val_loss: 2.3958 - val_accuracy: 0.2346\n",
            "Epoch 114/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.2487 - accuracy: 0.4286 - val_loss: 2.2791 - val_accuracy: 0.2778\n",
            "Epoch 115/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.1717 - accuracy: 0.4622 - val_loss: 1.8800 - val_accuracy: 0.2701\n",
            "Epoch 116/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.1757 - accuracy: 0.4720 - val_loss: 1.9799 - val_accuracy: 0.3086\n",
            "Epoch 117/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.2054 - accuracy: 0.4625 - val_loss: 1.9128 - val_accuracy: 0.3040\n",
            "Epoch 118/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.1611 - accuracy: 0.4817 - val_loss: 1.9701 - val_accuracy: 0.3210\n",
            "Epoch 119/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.2453 - accuracy: 0.4265 - val_loss: 1.8658 - val_accuracy: 0.2948\n",
            "Epoch 120/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.1695 - accuracy: 0.4754 - val_loss: 2.0005 - val_accuracy: 0.3241\n",
            "Epoch 121/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.1536 - accuracy: 0.4895 - val_loss: 1.6824 - val_accuracy: 0.2855\n",
            "Epoch 122/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.4038 - accuracy: 0.3862 - val_loss: 1.8319 - val_accuracy: 0.2485\n",
            "Epoch 123/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.2322 - accuracy: 0.4604 - val_loss: 2.3637 - val_accuracy: 0.2377\n",
            "Epoch 124/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.3939 - accuracy: 0.3777 - val_loss: 1.6674 - val_accuracy: 0.2670\n",
            "Epoch 125/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.2643 - accuracy: 0.4174 - val_loss: 2.0185 - val_accuracy: 0.3241\n",
            "Epoch 126/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.1868 - accuracy: 0.4665 - val_loss: 2.1358 - val_accuracy: 0.3133\n",
            "Epoch 127/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.2077 - accuracy: 0.4629 - val_loss: 2.3247 - val_accuracy: 0.2809\n",
            "Epoch 128/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.1569 - accuracy: 0.4802 - val_loss: 1.9591 - val_accuracy: 0.2870\n",
            "Epoch 129/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.1992 - accuracy: 0.4703 - val_loss: 1.9993 - val_accuracy: 0.2901\n",
            "Epoch 130/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.1689 - accuracy: 0.4778 - val_loss: 2.1777 - val_accuracy: 0.2948\n",
            "Epoch 131/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.1411 - accuracy: 0.4748 - val_loss: 2.7446 - val_accuracy: 0.2855\n",
            "Epoch 132/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.1412 - accuracy: 0.4821 - val_loss: 2.4093 - val_accuracy: 0.3133\n",
            "Epoch 133/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.0952 - accuracy: 0.4925 - val_loss: 2.4007 - val_accuracy: 0.3040\n",
            "Epoch 134/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.1297 - accuracy: 0.4967 - val_loss: 2.8329 - val_accuracy: 0.2623\n",
            "Epoch 135/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.1410 - accuracy: 0.4846 - val_loss: 2.4422 - val_accuracy: 0.2793\n",
            "Epoch 136/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.1209 - accuracy: 0.4950 - val_loss: 2.2977 - val_accuracy: 0.2948\n",
            "Epoch 137/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.1669 - accuracy: 0.4701 - val_loss: 2.1002 - val_accuracy: 0.2423\n",
            "Epoch 138/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.2499 - accuracy: 0.4067 - val_loss: 2.2595 - val_accuracy: 0.3287\n",
            "Epoch 139/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.1278 - accuracy: 0.4828 - val_loss: 2.0874 - val_accuracy: 0.3287\n",
            "Epoch 140/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.2765 - accuracy: 0.4543 - val_loss: 2.2068 - val_accuracy: 0.2731\n",
            "Epoch 141/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.1344 - accuracy: 0.4768 - val_loss: 2.1669 - val_accuracy: 0.3009\n",
            "Epoch 142/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.0928 - accuracy: 0.5052 - val_loss: 2.7260 - val_accuracy: 0.3256\n",
            "Epoch 143/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.3764 - accuracy: 0.4246 - val_loss: 1.6277 - val_accuracy: 0.2361\n",
            "Epoch 144/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5867 - accuracy: 0.2750 - val_loss: 1.7448 - val_accuracy: 0.1975\n",
            "Epoch 145/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5067 - accuracy: 0.3069 - val_loss: 1.6988 - val_accuracy: 0.2392\n",
            "Epoch 146/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.3188 - accuracy: 0.4319 - val_loss: 1.7318 - val_accuracy: 0.3025\n",
            "Epoch 147/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.2204 - accuracy: 0.4586 - val_loss: 1.9351 - val_accuracy: 0.2855\n",
            "Epoch 148/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.2870 - accuracy: 0.4051 - val_loss: 1.9275 - val_accuracy: 0.2500\n",
            "Epoch 149/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.2495 - accuracy: 0.4540 - val_loss: 1.7385 - val_accuracy: 0.2531\n",
            "Epoch 150/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.2518 - accuracy: 0.4396 - val_loss: 1.7335 - val_accuracy: 0.2870\n",
            "Epoch 151/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.2736 - accuracy: 0.4294 - val_loss: 1.8553 - val_accuracy: 0.3086\n",
            "Epoch 152/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.1820 - accuracy: 0.4796 - val_loss: 1.8221 - val_accuracy: 0.2901\n",
            "Epoch 153/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.2216 - accuracy: 0.4410 - val_loss: 1.9676 - val_accuracy: 0.3025\n",
            "Epoch 154/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.2053 - accuracy: 0.4516 - val_loss: 1.8820 - val_accuracy: 0.2948\n",
            "Epoch 155/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.1438 - accuracy: 0.4898 - val_loss: 2.0431 - val_accuracy: 0.2886\n",
            "Epoch 156/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.1203 - accuracy: 0.4844 - val_loss: 2.1099 - val_accuracy: 0.2608\n",
            "Epoch 157/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.1104 - accuracy: 0.4907 - val_loss: 2.0846 - val_accuracy: 0.2716\n",
            "Epoch 158/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.0941 - accuracy: 0.4993 - val_loss: 1.9650 - val_accuracy: 0.2978\n",
            "Epoch 159/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.1331 - accuracy: 0.4921 - val_loss: 2.3268 - val_accuracy: 0.2639\n",
            "Epoch 160/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.0935 - accuracy: 0.4995 - val_loss: 2.3162 - val_accuracy: 0.2747\n",
            "Epoch 161/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.1269 - accuracy: 0.4919 - val_loss: 2.1244 - val_accuracy: 0.2994\n",
            "Epoch 162/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.0820 - accuracy: 0.5089 - val_loss: 2.1935 - val_accuracy: 0.2824\n",
            "Epoch 163/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.0764 - accuracy: 0.5122 - val_loss: 2.7996 - val_accuracy: 0.2762\n",
            "Epoch 164/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.9619 - accuracy: 0.2814 - val_loss: 1.7087 - val_accuracy: 0.2562\n",
            "Epoch 165/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.4856 - accuracy: 0.2906 - val_loss: 1.7046 - val_accuracy: 0.2454\n",
            "Epoch 166/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.3576 - accuracy: 0.3593 - val_loss: 1.8114 - val_accuracy: 0.2994\n",
            "Epoch 167/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.2142 - accuracy: 0.4743 - val_loss: 1.9840 - val_accuracy: 0.2670\n",
            "Epoch 168/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.1194 - accuracy: 0.4935 - val_loss: 2.2262 - val_accuracy: 0.2948\n",
            "Epoch 169/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.2743 - accuracy: 0.4420 - val_loss: 1.8410 - val_accuracy: 0.2654\n",
            "Epoch 170/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.1302 - accuracy: 0.5036 - val_loss: 1.9861 - val_accuracy: 0.2731\n",
            "Epoch 171/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.0874 - accuracy: 0.5154 - val_loss: 2.6567 - val_accuracy: 0.2454\n",
            "Epoch 172/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.1727 - accuracy: 0.4778 - val_loss: 1.9690 - val_accuracy: 0.2886\n",
            "Epoch 173/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.1822 - accuracy: 0.4628 - val_loss: 1.9339 - val_accuracy: 0.3148\n",
            "Epoch 174/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.1463 - accuracy: 0.5034 - val_loss: 2.1141 - val_accuracy: 0.3071\n",
            "Epoch 175/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.1079 - accuracy: 0.4995 - val_loss: 2.1535 - val_accuracy: 0.2963\n",
            "Epoch 176/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.0998 - accuracy: 0.5024 - val_loss: 2.4128 - val_accuracy: 0.2793\n",
            "Epoch 177/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.0323 - accuracy: 0.5290 - val_loss: 2.4487 - val_accuracy: 0.2840\n",
            "Epoch 178/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.0510 - accuracy: 0.5249 - val_loss: 2.6253 - val_accuracy: 0.2593\n",
            "Epoch 179/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.0593 - accuracy: 0.5157 - val_loss: 2.5891 - val_accuracy: 0.2639\n",
            "Epoch 180/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.0433 - accuracy: 0.5293 - val_loss: 2.3553 - val_accuracy: 0.2978\n",
            "Epoch 181/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.0476 - accuracy: 0.5300 - val_loss: 3.0384 - val_accuracy: 0.3133\n",
            "Epoch 182/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.3214 - accuracy: 0.4468 - val_loss: 1.7762 - val_accuracy: 0.2500\n",
            "Epoch 183/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.1364 - accuracy: 0.4821 - val_loss: 1.8987 - val_accuracy: 0.2824\n",
            "Epoch 184/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.0791 - accuracy: 0.5001 - val_loss: 2.0864 - val_accuracy: 0.2994\n",
            "Epoch 185/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.0696 - accuracy: 0.4903 - val_loss: 2.2270 - val_accuracy: 0.2978\n",
            "Epoch 186/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.0836 - accuracy: 0.5014 - val_loss: 2.4091 - val_accuracy: 0.3086\n",
            "Epoch 187/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.0118 - accuracy: 0.5480 - val_loss: 2.2854 - val_accuracy: 0.2870\n",
            "Epoch 188/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 0.9873 - accuracy: 0.5493 - val_loss: 2.5960 - val_accuracy: 0.2793\n",
            "Epoch 189/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.0064 - accuracy: 0.5389 - val_loss: 2.2397 - val_accuracy: 0.3009\n",
            "Epoch 190/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.0400 - accuracy: 0.5429 - val_loss: 2.3278 - val_accuracy: 0.2731\n",
            "Epoch 191/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.0336 - accuracy: 0.5256 - val_loss: 2.3309 - val_accuracy: 0.2840\n",
            "Epoch 192/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 0.9936 - accuracy: 0.5640 - val_loss: 2.3708 - val_accuracy: 0.3179\n",
            "Epoch 193/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.0929 - accuracy: 0.5192 - val_loss: 2.2298 - val_accuracy: 0.2793\n",
            "Epoch 194/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.0401 - accuracy: 0.5338 - val_loss: 2.2515 - val_accuracy: 0.3164\n",
            "Epoch 195/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 0.9893 - accuracy: 0.5490 - val_loss: 2.7863 - val_accuracy: 0.2778\n",
            "Epoch 196/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 0.9878 - accuracy: 0.5541 - val_loss: 2.5992 - val_accuracy: 0.3133\n",
            "Epoch 197/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 0.9567 - accuracy: 0.5613 - val_loss: 2.8261 - val_accuracy: 0.2932\n",
            "Epoch 198/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 0.9262 - accuracy: 0.5867 - val_loss: 2.7872 - val_accuracy: 0.2855\n",
            "Epoch 199/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.1110 - accuracy: 0.5083 - val_loss: 2.4099 - val_accuracy: 0.2716\n",
            "Epoch 200/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.4747 - accuracy: 0.4345 - val_loss: 1.9210 - val_accuracy: 0.2346\n",
            "Processing Fold # 3\n",
            "Epoch 1/200\n",
            "16/16 [==============================] - 6s 328ms/step - loss: 2.5540 - accuracy: 0.2404 - val_loss: 2.4706 - val_accuracy: 0.2083\n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 2.3790 - accuracy: 0.2371 - val_loss: 1.8555 - val_accuracy: 0.2114\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.8131 - accuracy: 0.2571 - val_loss: 1.6632 - val_accuracy: 0.2052\n",
            "Epoch 4/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6458 - accuracy: 0.1935 - val_loss: 1.6100 - val_accuracy: 0.1867\n",
            "Epoch 5/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.6090 - accuracy: 0.1720 - val_loss: 1.6108 - val_accuracy: 0.1867\n",
            "Epoch 6/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.6116 - accuracy: 0.1795 - val_loss: 1.6146 - val_accuracy: 0.2284\n",
            "Epoch 7/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.6116 - accuracy: 0.2309 - val_loss: 1.6129 - val_accuracy: 0.2269\n",
            "Epoch 8/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.6103 - accuracy: 0.2401 - val_loss: 1.6067 - val_accuracy: 0.2130\n",
            "Epoch 9/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6031 - accuracy: 0.2294 - val_loss: 1.6093 - val_accuracy: 0.1867\n",
            "Epoch 10/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.6085 - accuracy: 0.2056 - val_loss: 1.6089 - val_accuracy: 0.2299\n",
            "Epoch 11/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.6093 - accuracy: 0.2412 - val_loss: 1.6086 - val_accuracy: 0.2299\n",
            "Epoch 12/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6066 - accuracy: 0.2556 - val_loss: 1.6051 - val_accuracy: 0.1435\n",
            "Epoch 13/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6008 - accuracy: 0.2307 - val_loss: 1.5995 - val_accuracy: 0.2299\n",
            "Epoch 14/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.6115 - accuracy: 0.2196 - val_loss: 1.6084 - val_accuracy: 0.2299\n",
            "Epoch 15/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5977 - accuracy: 0.2437 - val_loss: 1.6059 - val_accuracy: 0.2299\n",
            "Epoch 16/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5986 - accuracy: 0.2551 - val_loss: 1.6076 - val_accuracy: 0.2299\n",
            "Epoch 17/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6046 - accuracy: 0.2536 - val_loss: 1.6074 - val_accuracy: 0.2299\n",
            "Epoch 18/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6026 - accuracy: 0.2575 - val_loss: 1.6071 - val_accuracy: 0.2299\n",
            "Epoch 19/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6034 - accuracy: 0.2476 - val_loss: 1.6069 - val_accuracy: 0.2299\n",
            "Epoch 20/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6029 - accuracy: 0.2497 - val_loss: 1.6067 - val_accuracy: 0.2299\n",
            "Epoch 21/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6024 - accuracy: 0.2484 - val_loss: 1.6066 - val_accuracy: 0.2299\n",
            "Epoch 22/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6014 - accuracy: 0.2474 - val_loss: 1.6064 - val_accuracy: 0.2299\n",
            "Epoch 23/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.6021 - accuracy: 0.2461 - val_loss: 1.6063 - val_accuracy: 0.2299\n",
            "Epoch 24/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5986 - accuracy: 0.2570 - val_loss: 1.6063 - val_accuracy: 0.2299\n",
            "Epoch 25/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5953 - accuracy: 0.2629 - val_loss: 1.6062 - val_accuracy: 0.2299\n",
            "Epoch 26/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.6005 - accuracy: 0.2455 - val_loss: 1.6062 - val_accuracy: 0.2299\n",
            "Epoch 27/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5972 - accuracy: 0.2586 - val_loss: 1.6062 - val_accuracy: 0.2299\n",
            "Epoch 28/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5982 - accuracy: 0.2455 - val_loss: 1.6062 - val_accuracy: 0.2299\n",
            "Epoch 29/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5990 - accuracy: 0.2384 - val_loss: 1.6062 - val_accuracy: 0.2299\n",
            "Epoch 30/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5968 - accuracy: 0.2567 - val_loss: 1.6062 - val_accuracy: 0.2299\n",
            "Epoch 31/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5985 - accuracy: 0.2500 - val_loss: 1.6063 - val_accuracy: 0.2299\n",
            "Epoch 32/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5985 - accuracy: 0.2492 - val_loss: 1.6064 - val_accuracy: 0.2299\n",
            "Epoch 33/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6005 - accuracy: 0.2354 - val_loss: 1.6065 - val_accuracy: 0.2299\n",
            "Epoch 34/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5976 - accuracy: 0.2391 - val_loss: 1.6066 - val_accuracy: 0.2299\n",
            "Epoch 35/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5966 - accuracy: 0.2453 - val_loss: 1.6067 - val_accuracy: 0.2299\n",
            "Epoch 36/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6014 - accuracy: 0.2344 - val_loss: 1.6068 - val_accuracy: 0.2299\n",
            "Epoch 37/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6005 - accuracy: 0.2404 - val_loss: 1.6069 - val_accuracy: 0.2299\n",
            "Epoch 38/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5975 - accuracy: 0.2491 - val_loss: 1.6070 - val_accuracy: 0.2299\n",
            "Epoch 39/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5963 - accuracy: 0.2404 - val_loss: 1.6071 - val_accuracy: 0.2299\n",
            "Epoch 40/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5963 - accuracy: 0.2476 - val_loss: 1.6072 - val_accuracy: 0.2299\n",
            "Epoch 41/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5916 - accuracy: 0.2587 - val_loss: 1.6073 - val_accuracy: 0.2299\n",
            "Epoch 42/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5952 - accuracy: 0.2542 - val_loss: 1.6073 - val_accuracy: 0.2299\n",
            "Epoch 43/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5991 - accuracy: 0.2400 - val_loss: 1.6074 - val_accuracy: 0.2299\n",
            "Epoch 44/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5977 - accuracy: 0.2410 - val_loss: 1.6075 - val_accuracy: 0.2299\n",
            "Epoch 45/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.5961 - accuracy: 0.2481 - val_loss: 1.6077 - val_accuracy: 0.2299\n",
            "Epoch 46/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5981 - accuracy: 0.2416 - val_loss: 1.6078 - val_accuracy: 0.2299\n",
            "Epoch 47/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5905 - accuracy: 0.2521 - val_loss: 1.6080 - val_accuracy: 0.2299\n",
            "Epoch 48/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.5954 - accuracy: 0.2409 - val_loss: 1.6080 - val_accuracy: 0.2299\n",
            "Epoch 49/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5942 - accuracy: 0.2573 - val_loss: 1.6080 - val_accuracy: 0.2299\n",
            "Epoch 50/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5975 - accuracy: 0.2381 - val_loss: 1.6081 - val_accuracy: 0.2299\n",
            "Epoch 51/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5910 - accuracy: 0.2557 - val_loss: 1.6082 - val_accuracy: 0.2299\n",
            "Epoch 52/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5917 - accuracy: 0.2512 - val_loss: 1.6083 - val_accuracy: 0.2299\n",
            "Epoch 53/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5966 - accuracy: 0.2415 - val_loss: 1.6083 - val_accuracy: 0.2299\n",
            "Epoch 54/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5931 - accuracy: 0.2414 - val_loss: 1.6085 - val_accuracy: 0.2299\n",
            "Epoch 55/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5906 - accuracy: 0.2566 - val_loss: 1.6086 - val_accuracy: 0.2299\n",
            "Epoch 56/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5975 - accuracy: 0.2558 - val_loss: 1.6086 - val_accuracy: 0.2299\n",
            "Epoch 57/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5928 - accuracy: 0.2552 - val_loss: 1.6087 - val_accuracy: 0.2299\n",
            "Epoch 58/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5981 - accuracy: 0.2323 - val_loss: 1.6087 - val_accuracy: 0.2299\n",
            "Epoch 59/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5942 - accuracy: 0.2571 - val_loss: 1.6089 - val_accuracy: 0.2299\n",
            "Epoch 60/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.6009 - accuracy: 0.2300 - val_loss: 1.6089 - val_accuracy: 0.2299\n",
            "Epoch 61/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5921 - accuracy: 0.2422 - val_loss: 1.6091 - val_accuracy: 0.2299\n",
            "Epoch 62/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5930 - accuracy: 0.2441 - val_loss: 1.6091 - val_accuracy: 0.2299\n",
            "Epoch 63/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5930 - accuracy: 0.2478 - val_loss: 1.6092 - val_accuracy: 0.2299\n",
            "Epoch 64/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5970 - accuracy: 0.2336 - val_loss: 1.6091 - val_accuracy: 0.2299\n",
            "Epoch 65/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5979 - accuracy: 0.2516 - val_loss: 1.6091 - val_accuracy: 0.2299\n",
            "Epoch 66/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.5932 - accuracy: 0.2502 - val_loss: 1.6091 - val_accuracy: 0.2299\n",
            "Epoch 67/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5970 - accuracy: 0.2460 - val_loss: 1.6092 - val_accuracy: 0.2299\n",
            "Epoch 68/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5945 - accuracy: 0.2444 - val_loss: 1.6093 - val_accuracy: 0.2299\n",
            "Epoch 69/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5975 - accuracy: 0.2450 - val_loss: 1.6093 - val_accuracy: 0.2299\n",
            "Epoch 70/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5946 - accuracy: 0.2472 - val_loss: 1.6095 - val_accuracy: 0.2299\n",
            "Epoch 71/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5938 - accuracy: 0.2472 - val_loss: 1.6095 - val_accuracy: 0.2299\n",
            "Epoch 72/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5982 - accuracy: 0.2460 - val_loss: 1.6095 - val_accuracy: 0.2299\n",
            "Epoch 73/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5928 - accuracy: 0.2449 - val_loss: 1.6096 - val_accuracy: 0.2299\n",
            "Epoch 74/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5969 - accuracy: 0.2383 - val_loss: 1.6097 - val_accuracy: 0.2299\n",
            "Epoch 75/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5960 - accuracy: 0.2463 - val_loss: 1.6098 - val_accuracy: 0.2299\n",
            "Epoch 76/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5939 - accuracy: 0.2555 - val_loss: 1.6098 - val_accuracy: 0.2299\n",
            "Epoch 77/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5952 - accuracy: 0.2494 - val_loss: 1.6098 - val_accuracy: 0.2299\n",
            "Epoch 78/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5953 - accuracy: 0.2512 - val_loss: 1.6099 - val_accuracy: 0.2299\n",
            "Epoch 79/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5913 - accuracy: 0.2599 - val_loss: 1.6099 - val_accuracy: 0.2299\n",
            "Epoch 80/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5987 - accuracy: 0.2404 - val_loss: 1.6099 - val_accuracy: 0.2299\n",
            "Epoch 81/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5935 - accuracy: 0.2514 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 82/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5921 - accuracy: 0.2485 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 83/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5947 - accuracy: 0.2452 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 84/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5939 - accuracy: 0.2471 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 85/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5936 - accuracy: 0.2537 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 86/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5937 - accuracy: 0.2478 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 87/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5994 - accuracy: 0.2364 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 88/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5956 - accuracy: 0.2448 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 89/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5926 - accuracy: 0.2579 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 90/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5950 - accuracy: 0.2443 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 91/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5921 - accuracy: 0.2484 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 92/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5936 - accuracy: 0.2497 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 93/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5963 - accuracy: 0.2510 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 94/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5967 - accuracy: 0.2459 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 95/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5986 - accuracy: 0.2310 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 96/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5967 - accuracy: 0.2565 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 97/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5913 - accuracy: 0.2530 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 98/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5939 - accuracy: 0.2553 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 99/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5976 - accuracy: 0.2406 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 100/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5985 - accuracy: 0.2312 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 101/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.6000 - accuracy: 0.2465 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 102/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5944 - accuracy: 0.2402 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 103/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5939 - accuracy: 0.2459 - val_loss: 1.6104 - val_accuracy: 0.2299\n",
            "Epoch 104/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5932 - accuracy: 0.2535 - val_loss: 1.6104 - val_accuracy: 0.2299\n",
            "Epoch 105/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5974 - accuracy: 0.2543 - val_loss: 1.6104 - val_accuracy: 0.2299\n",
            "Epoch 106/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5934 - accuracy: 0.2447 - val_loss: 1.6105 - val_accuracy: 0.2299\n",
            "Epoch 107/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5952 - accuracy: 0.2463 - val_loss: 1.6105 - val_accuracy: 0.2299\n",
            "Epoch 108/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5943 - accuracy: 0.2522 - val_loss: 1.6105 - val_accuracy: 0.2299\n",
            "Epoch 109/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5951 - accuracy: 0.2482 - val_loss: 1.6105 - val_accuracy: 0.2299\n",
            "Epoch 110/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5957 - accuracy: 0.2525 - val_loss: 1.6106 - val_accuracy: 0.2299\n",
            "Epoch 111/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5910 - accuracy: 0.2467 - val_loss: 1.6106 - val_accuracy: 0.2299\n",
            "Epoch 112/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5992 - accuracy: 0.2395 - val_loss: 1.6105 - val_accuracy: 0.2299\n",
            "Epoch 113/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5956 - accuracy: 0.2509 - val_loss: 1.6105 - val_accuracy: 0.2299\n",
            "Epoch 114/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5944 - accuracy: 0.2513 - val_loss: 1.6104 - val_accuracy: 0.2299\n",
            "Epoch 115/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5935 - accuracy: 0.2473 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 116/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5970 - accuracy: 0.2430 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 117/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5932 - accuracy: 0.2555 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 118/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5980 - accuracy: 0.2432 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 119/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5942 - accuracy: 0.2331 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 120/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5928 - accuracy: 0.2605 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 121/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5965 - accuracy: 0.2474 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 122/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5937 - accuracy: 0.2389 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 123/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5914 - accuracy: 0.2519 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 124/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5985 - accuracy: 0.2352 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 125/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5908 - accuracy: 0.2535 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 126/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5971 - accuracy: 0.2390 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 127/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5979 - accuracy: 0.2352 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 128/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5976 - accuracy: 0.2544 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 129/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5923 - accuracy: 0.2473 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 130/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5950 - accuracy: 0.2446 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 131/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5934 - accuracy: 0.2543 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 132/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5905 - accuracy: 0.2481 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 133/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5968 - accuracy: 0.2360 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 134/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.6002 - accuracy: 0.2312 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 135/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5985 - accuracy: 0.2393 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 136/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.5992 - accuracy: 0.2461 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 137/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5951 - accuracy: 0.2381 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 138/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5957 - accuracy: 0.2488 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 139/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5967 - accuracy: 0.2427 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 140/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5904 - accuracy: 0.2634 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 141/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5921 - accuracy: 0.2528 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 142/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5934 - accuracy: 0.2574 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 143/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5983 - accuracy: 0.2439 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 144/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5922 - accuracy: 0.2424 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 145/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5913 - accuracy: 0.2469 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 146/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5924 - accuracy: 0.2488 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 147/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5896 - accuracy: 0.2629 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 148/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5949 - accuracy: 0.2416 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 149/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5928 - accuracy: 0.2457 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 150/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5916 - accuracy: 0.2568 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 151/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5965 - accuracy: 0.2427 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 152/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5945 - accuracy: 0.2497 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 153/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5967 - accuracy: 0.2428 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 154/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5943 - accuracy: 0.2450 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 155/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5964 - accuracy: 0.2373 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 156/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5918 - accuracy: 0.2557 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 157/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5955 - accuracy: 0.2438 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 158/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5941 - accuracy: 0.2437 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 159/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5947 - accuracy: 0.2474 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 160/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5929 - accuracy: 0.2306 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 161/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5960 - accuracy: 0.2466 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 162/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5929 - accuracy: 0.2528 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 163/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5924 - accuracy: 0.2402 - val_loss: 1.6099 - val_accuracy: 0.2299\n",
            "Epoch 164/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.6011 - accuracy: 0.2276 - val_loss: 1.6099 - val_accuracy: 0.2299\n",
            "Epoch 165/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5949 - accuracy: 0.2478 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 166/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.5948 - accuracy: 0.2491 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 167/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5973 - accuracy: 0.2432 - val_loss: 1.6099 - val_accuracy: 0.2299\n",
            "Epoch 168/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5920 - accuracy: 0.2524 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 169/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5957 - accuracy: 0.2518 - val_loss: 1.6099 - val_accuracy: 0.2299\n",
            "Epoch 170/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5932 - accuracy: 0.2355 - val_loss: 1.6098 - val_accuracy: 0.2299\n",
            "Epoch 171/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5947 - accuracy: 0.2468 - val_loss: 1.6098 - val_accuracy: 0.2299\n",
            "Epoch 172/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5983 - accuracy: 0.2374 - val_loss: 1.6098 - val_accuracy: 0.2299\n",
            "Epoch 173/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5920 - accuracy: 0.2461 - val_loss: 1.6099 - val_accuracy: 0.2299\n",
            "Epoch 174/200\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.5915 - accuracy: 0.2600 - val_loss: 1.6099 - val_accuracy: 0.2299\n",
            "Epoch 175/200\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.5966 - accuracy: 0.2388 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 176/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5943 - accuracy: 0.2375 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 177/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5955 - accuracy: 0.2522 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 178/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5929 - accuracy: 0.2427 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 179/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5990 - accuracy: 0.2380 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 180/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5935 - accuracy: 0.2505 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 181/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5982 - accuracy: 0.2350 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 182/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5990 - accuracy: 0.2390 - val_loss: 1.6103 - val_accuracy: 0.2299\n",
            "Epoch 183/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5971 - accuracy: 0.2469 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 184/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5959 - accuracy: 0.2516 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 185/200\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.5970 - accuracy: 0.2440 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 186/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5967 - accuracy: 0.2450 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 187/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5939 - accuracy: 0.2540 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 188/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5956 - accuracy: 0.2364 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 189/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5935 - accuracy: 0.2414 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 190/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5954 - accuracy: 0.2559 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 191/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.5935 - accuracy: 0.2357 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 192/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5934 - accuracy: 0.2548 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 193/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5967 - accuracy: 0.2446 - val_loss: 1.6102 - val_accuracy: 0.2299\n",
            "Epoch 194/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5957 - accuracy: 0.2473 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 195/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5945 - accuracy: 0.2554 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 196/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5905 - accuracy: 0.2433 - val_loss: 1.6101 - val_accuracy: 0.2299\n",
            "Epoch 197/200\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.5933 - accuracy: 0.2552 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 198/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5960 - accuracy: 0.2403 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 199/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5930 - accuracy: 0.2549 - val_loss: 1.6100 - val_accuracy: 0.2299\n",
            "Epoch 200/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5936 - accuracy: 0.2460 - val_loss: 1.6099 - val_accuracy: 0.2299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9o95jkIF0mO",
        "outputId": "cea29afb-aaf3-41f8-d119-0d58280f55fb"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images,test_labels)\n",
        "print(\"test accuracy is :\", test_accuracy)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 3s 49ms/step - loss: 1.5994 - accuracy: 0.2457\n",
            "test accuracy is : 0.24566474556922913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny0ClamEF4mf"
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(100, activation='relu',input_shape=(150*150,)))\n",
        "model.add(layers.Dense(80, activation='relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(80, activation='relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(50, activation='relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(40, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M7nk0NpF95Y",
        "outputId": "a2d056e7-e194-46f7-d356-828a1062bb4c"
      },
      "source": [
        "history = model.fit(train_images, train_labels, epochs=250, batch_size=128)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "21/21 [==============================] - 2s 45ms/step - loss: 3.7429 - accuracy: 0.2066\n",
            "Epoch 2/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.7206 - accuracy: 0.2104\n",
            "Epoch 3/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.6304 - accuracy: 0.2295\n",
            "Epoch 4/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.6087 - accuracy: 0.2434\n",
            "Epoch 5/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.5800 - accuracy: 0.2693\n",
            "Epoch 6/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.5797 - accuracy: 0.2714\n",
            "Epoch 7/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.5597 - accuracy: 0.2930\n",
            "Epoch 8/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.5521 - accuracy: 0.2886\n",
            "Epoch 9/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.5469 - accuracy: 0.2857\n",
            "Epoch 10/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.5381 - accuracy: 0.3006\n",
            "Epoch 11/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.5409 - accuracy: 0.2738\n",
            "Epoch 12/250\n",
            "21/21 [==============================] - 1s 44ms/step - loss: 1.5318 - accuracy: 0.2939\n",
            "Epoch 13/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.5344 - accuracy: 0.2989\n",
            "Epoch 14/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.5315 - accuracy: 0.3034\n",
            "Epoch 15/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.5285 - accuracy: 0.3029\n",
            "Epoch 16/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.5148 - accuracy: 0.3077\n",
            "Epoch 17/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.5279 - accuracy: 0.2946\n",
            "Epoch 18/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.5133 - accuracy: 0.3133\n",
            "Epoch 19/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.5004 - accuracy: 0.3133\n",
            "Epoch 20/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.5007 - accuracy: 0.3096\n",
            "Epoch 21/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.5063 - accuracy: 0.3260\n",
            "Epoch 22/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4894 - accuracy: 0.3212\n",
            "Epoch 23/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.5057 - accuracy: 0.3228\n",
            "Epoch 24/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.4835 - accuracy: 0.3263\n",
            "Epoch 25/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4857 - accuracy: 0.3266\n",
            "Epoch 26/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.4726 - accuracy: 0.3327\n",
            "Epoch 27/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4873 - accuracy: 0.3201\n",
            "Epoch 28/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.4979 - accuracy: 0.3394\n",
            "Epoch 29/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.4838 - accuracy: 0.3431\n",
            "Epoch 30/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4624 - accuracy: 0.3464\n",
            "Epoch 31/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.4439 - accuracy: 0.3583\n",
            "Epoch 32/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4509 - accuracy: 0.3615\n",
            "Epoch 33/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.4470 - accuracy: 0.3652\n",
            "Epoch 34/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.4419 - accuracy: 0.3500\n",
            "Epoch 35/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.4456 - accuracy: 0.3498\n",
            "Epoch 36/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4277 - accuracy: 0.3546\n",
            "Epoch 37/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.4773 - accuracy: 0.3457\n",
            "Epoch 38/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.3994 - accuracy: 0.4028\n",
            "Epoch 39/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4577 - accuracy: 0.3624\n",
            "Epoch 40/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3841 - accuracy: 0.4011\n",
            "Epoch 41/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4421 - accuracy: 0.3690\n",
            "Epoch 42/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.4251 - accuracy: 0.3797\n",
            "Epoch 43/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4197 - accuracy: 0.3759\n",
            "Epoch 44/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.4337 - accuracy: 0.3685\n",
            "Epoch 45/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.3897 - accuracy: 0.3903\n",
            "Epoch 46/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.3990 - accuracy: 0.3947\n",
            "Epoch 47/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3922 - accuracy: 0.3802\n",
            "Epoch 48/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4620 - accuracy: 0.3743\n",
            "Epoch 49/250\n",
            "21/21 [==============================] - 1s 44ms/step - loss: 1.4091 - accuracy: 0.3737\n",
            "Epoch 50/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4111 - accuracy: 0.3667\n",
            "Epoch 51/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3628 - accuracy: 0.4002\n",
            "Epoch 52/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3768 - accuracy: 0.4071\n",
            "Epoch 53/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3972 - accuracy: 0.3819\n",
            "Epoch 54/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3711 - accuracy: 0.3945\n",
            "Epoch 55/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3961 - accuracy: 0.3845\n",
            "Epoch 56/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4475 - accuracy: 0.3901\n",
            "Epoch 57/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3651 - accuracy: 0.4014\n",
            "Epoch 58/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.3486 - accuracy: 0.3957\n",
            "Epoch 59/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4087 - accuracy: 0.3971\n",
            "Epoch 60/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.4714 - accuracy: 0.4091\n",
            "Epoch 61/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3519 - accuracy: 0.4148\n",
            "Epoch 62/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3649 - accuracy: 0.4003\n",
            "Epoch 63/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3634 - accuracy: 0.4073\n",
            "Epoch 64/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3531 - accuracy: 0.4123\n",
            "Epoch 65/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3637 - accuracy: 0.3987\n",
            "Epoch 66/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3732 - accuracy: 0.4160\n",
            "Epoch 67/250\n",
            "21/21 [==============================] - 1s 44ms/step - loss: 1.2934 - accuracy: 0.4406\n",
            "Epoch 68/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3438 - accuracy: 0.4038\n",
            "Epoch 69/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3140 - accuracy: 0.4226\n",
            "Epoch 70/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3566 - accuracy: 0.4082\n",
            "Epoch 71/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3358 - accuracy: 0.4197\n",
            "Epoch 72/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.2873 - accuracy: 0.4512\n",
            "Epoch 73/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.3256 - accuracy: 0.4219\n",
            "Epoch 74/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3293 - accuracy: 0.4147\n",
            "Epoch 75/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.3679 - accuracy: 0.3955\n",
            "Epoch 76/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3445 - accuracy: 0.3990\n",
            "Epoch 77/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.5160 - accuracy: 0.4098\n",
            "Epoch 78/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2554 - accuracy: 0.4510\n",
            "Epoch 79/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3974 - accuracy: 0.3900\n",
            "Epoch 80/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2741 - accuracy: 0.4609\n",
            "Epoch 81/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2998 - accuracy: 0.4284\n",
            "Epoch 82/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2648 - accuracy: 0.4530\n",
            "Epoch 83/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2994 - accuracy: 0.4213\n",
            "Epoch 84/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3814 - accuracy: 0.4216\n",
            "Epoch 85/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.7677 - accuracy: 0.3931\n",
            "Epoch 86/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3140 - accuracy: 0.4227\n",
            "Epoch 87/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2638 - accuracy: 0.4400\n",
            "Epoch 88/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.3197 - accuracy: 0.4286\n",
            "Epoch 89/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2451 - accuracy: 0.4614\n",
            "Epoch 90/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4743 - accuracy: 0.4018\n",
            "Epoch 91/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.2301 - accuracy: 0.4730\n",
            "Epoch 92/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2465 - accuracy: 0.4565\n",
            "Epoch 93/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2700 - accuracy: 0.4502\n",
            "Epoch 94/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.2971 - accuracy: 0.4354\n",
            "Epoch 95/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.2433 - accuracy: 0.4706\n",
            "Epoch 96/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3314 - accuracy: 0.4246\n",
            "Epoch 97/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.2785 - accuracy: 0.4539\n",
            "Epoch 98/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.3085 - accuracy: 0.4294\n",
            "Epoch 99/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3625 - accuracy: 0.4190\n",
            "Epoch 100/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2096 - accuracy: 0.4656\n",
            "Epoch 101/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3274 - accuracy: 0.4371\n",
            "Epoch 102/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2301 - accuracy: 0.4590\n",
            "Epoch 103/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2902 - accuracy: 0.4539\n",
            "Epoch 104/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.2693 - accuracy: 0.4577\n",
            "Epoch 105/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2415 - accuracy: 0.4565\n",
            "Epoch 106/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2406 - accuracy: 0.4559\n",
            "Epoch 107/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.2810 - accuracy: 0.4432\n",
            "Epoch 108/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2387 - accuracy: 0.4586\n",
            "Epoch 109/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2500 - accuracy: 0.4450\n",
            "Epoch 110/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2874 - accuracy: 0.4267\n",
            "Epoch 111/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2963 - accuracy: 0.4591\n",
            "Epoch 112/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3724 - accuracy: 0.4365\n",
            "Epoch 113/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3601 - accuracy: 0.4643\n",
            "Epoch 114/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2827 - accuracy: 0.4417\n",
            "Epoch 115/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.2937 - accuracy: 0.4498\n",
            "Epoch 116/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.3756 - accuracy: 0.4329\n",
            "Epoch 117/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.5299 - accuracy: 0.4330\n",
            "Epoch 118/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1951 - accuracy: 0.4723\n",
            "Epoch 119/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.1649 - accuracy: 0.4969\n",
            "Epoch 120/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2215 - accuracy: 0.4721\n",
            "Epoch 121/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.2821 - accuracy: 0.4529\n",
            "Epoch 122/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2693 - accuracy: 0.4553\n",
            "Epoch 123/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.2234 - accuracy: 0.4829\n",
            "Epoch 124/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2918 - accuracy: 0.4592\n",
            "Epoch 125/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1539 - accuracy: 0.4964\n",
            "Epoch 126/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1679 - accuracy: 0.4997\n",
            "Epoch 127/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2715 - accuracy: 0.4560\n",
            "Epoch 128/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2180 - accuracy: 0.4753\n",
            "Epoch 129/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3572 - accuracy: 0.4417\n",
            "Epoch 130/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.2314 - accuracy: 0.4766\n",
            "Epoch 131/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.2667 - accuracy: 0.4628\n",
            "Epoch 132/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1760 - accuracy: 0.4904\n",
            "Epoch 133/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1922 - accuracy: 0.4905\n",
            "Epoch 134/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.4389 - accuracy: 0.4630\n",
            "Epoch 135/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.2135 - accuracy: 0.4625\n",
            "Epoch 136/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.2340 - accuracy: 0.4706\n",
            "Epoch 137/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2463 - accuracy: 0.4620\n",
            "Epoch 138/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.3032 - accuracy: 0.4872\n",
            "Epoch 139/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1825 - accuracy: 0.4900\n",
            "Epoch 140/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3046 - accuracy: 0.4622\n",
            "Epoch 141/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.1728 - accuracy: 0.4990\n",
            "Epoch 142/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2129 - accuracy: 0.4731\n",
            "Epoch 143/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1672 - accuracy: 0.4986\n",
            "Epoch 144/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1697 - accuracy: 0.4940\n",
            "Epoch 145/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1802 - accuracy: 0.4768\n",
            "Epoch 146/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1710 - accuracy: 0.4889\n",
            "Epoch 147/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1775 - accuracy: 0.4800\n",
            "Epoch 148/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1702 - accuracy: 0.4899\n",
            "Epoch 149/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.0999 - accuracy: 0.5230\n",
            "Epoch 150/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.2624 - accuracy: 0.4425\n",
            "Epoch 151/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.2842 - accuracy: 0.4675\n",
            "Epoch 152/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1478 - accuracy: 0.5056\n",
            "Epoch 153/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.2917 - accuracy: 0.4762\n",
            "Epoch 154/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.1619 - accuracy: 0.4922\n",
            "Epoch 155/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1211 - accuracy: 0.4892\n",
            "Epoch 156/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1963 - accuracy: 0.4760\n",
            "Epoch 157/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.2602 - accuracy: 0.4670\n",
            "Epoch 158/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1647 - accuracy: 0.5031\n",
            "Epoch 159/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2462 - accuracy: 0.4862\n",
            "Epoch 160/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3754 - accuracy: 0.4882\n",
            "Epoch 161/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1330 - accuracy: 0.5083\n",
            "Epoch 162/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1326 - accuracy: 0.5063\n",
            "Epoch 163/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.2441 - accuracy: 0.4668\n",
            "Epoch 164/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1328 - accuracy: 0.5314\n",
            "Epoch 165/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1751 - accuracy: 0.4948\n",
            "Epoch 166/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1188 - accuracy: 0.5108\n",
            "Epoch 167/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1354 - accuracy: 0.5107\n",
            "Epoch 168/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.2115 - accuracy: 0.4986\n",
            "Epoch 169/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.3192 - accuracy: 0.4564\n",
            "Epoch 170/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1671 - accuracy: 0.5027\n",
            "Epoch 171/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1089 - accuracy: 0.5063\n",
            "Epoch 172/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1680 - accuracy: 0.4929\n",
            "Epoch 173/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1386 - accuracy: 0.5123\n",
            "Epoch 174/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1188 - accuracy: 0.5227\n",
            "Epoch 175/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1283 - accuracy: 0.5186\n",
            "Epoch 176/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1321 - accuracy: 0.5273\n",
            "Epoch 177/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.0966 - accuracy: 0.5189\n",
            "Epoch 178/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1361 - accuracy: 0.5048\n",
            "Epoch 179/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1273 - accuracy: 0.5176\n",
            "Epoch 180/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1222 - accuracy: 0.5158\n",
            "Epoch 181/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.0972 - accuracy: 0.5255\n",
            "Epoch 182/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1014 - accuracy: 0.5304\n",
            "Epoch 183/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2322 - accuracy: 0.4978\n",
            "Epoch 184/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1371 - accuracy: 0.4966\n",
            "Epoch 185/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1173 - accuracy: 0.5195\n",
            "Epoch 186/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1647 - accuracy: 0.4829\n",
            "Epoch 187/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.2312 - accuracy: 0.4923\n",
            "Epoch 188/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.0072 - accuracy: 0.5588\n",
            "Epoch 189/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1230 - accuracy: 0.5243\n",
            "Epoch 190/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1304 - accuracy: 0.5385\n",
            "Epoch 191/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1478 - accuracy: 0.5094\n",
            "Epoch 192/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.1200 - accuracy: 0.5219\n",
            "Epoch 193/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.2383 - accuracy: 0.4960\n",
            "Epoch 194/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2131 - accuracy: 0.5100\n",
            "Epoch 195/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1454 - accuracy: 0.5022\n",
            "Epoch 196/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.0746 - accuracy: 0.5403\n",
            "Epoch 197/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1976 - accuracy: 0.5125\n",
            "Epoch 198/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1229 - accuracy: 0.5153\n",
            "Epoch 199/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.3139 - accuracy: 0.4873\n",
            "Epoch 200/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.2245 - accuracy: 0.4752\n",
            "Epoch 201/250\n",
            "21/21 [==============================] - 1s 45ms/step - loss: 1.1644 - accuracy: 0.5021\n",
            "Epoch 202/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.0649 - accuracy: 0.5394\n",
            "Epoch 203/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1050 - accuracy: 0.5211\n",
            "Epoch 204/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1387 - accuracy: 0.5159\n",
            "Epoch 205/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.0937 - accuracy: 0.5222\n",
            "Epoch 206/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.0561 - accuracy: 0.5597\n",
            "Epoch 207/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.0464 - accuracy: 0.5609\n",
            "Epoch 208/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.0954 - accuracy: 0.5243\n",
            "Epoch 209/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1613 - accuracy: 0.5028\n",
            "Epoch 210/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1166 - accuracy: 0.5160\n",
            "Epoch 211/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1217 - accuracy: 0.5167\n",
            "Epoch 212/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.2368 - accuracy: 0.5011\n",
            "Epoch 213/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.0942 - accuracy: 0.5543\n",
            "Epoch 214/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.0722 - accuracy: 0.5401\n",
            "Epoch 215/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1967 - accuracy: 0.5075\n",
            "Epoch 216/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.0785 - accuracy: 0.5407\n",
            "Epoch 217/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1529 - accuracy: 0.5264\n",
            "Epoch 218/250\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.4910 - accuracy: 0.4795\n",
            "Epoch 219/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.0904 - accuracy: 0.5403\n",
            "Epoch 220/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.2348 - accuracy: 0.5048\n",
            "Epoch 221/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1354 - accuracy: 0.5053\n",
            "Epoch 222/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1561 - accuracy: 0.5098\n",
            "Epoch 223/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.1627 - accuracy: 0.5316\n",
            "Epoch 224/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.1167 - accuracy: 0.5255\n",
            "Epoch 225/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.1116 - accuracy: 0.5313\n",
            "Epoch 226/250\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.0301 - accuracy: 0.5484\n",
            "Epoch 227/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.1706 - accuracy: 0.5088\n",
            "Epoch 228/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.0848 - accuracy: 0.5369\n",
            "Epoch 229/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1092 - accuracy: 0.5247\n",
            "Epoch 230/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.0377 - accuracy: 0.5523\n",
            "Epoch 231/250\n",
            "21/21 [==============================] - 1s 46ms/step - loss: 1.1473 - accuracy: 0.5162\n",
            "Epoch 232/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.1446 - accuracy: 0.5220\n",
            "Epoch 233/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.2277 - accuracy: 0.5025\n",
            "Epoch 234/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1304 - accuracy: 0.5250\n",
            "Epoch 235/250\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.0544 - accuracy: 0.5589\n",
            "Epoch 236/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1236 - accuracy: 0.5519\n",
            "Epoch 237/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.0311 - accuracy: 0.5546\n",
            "Epoch 238/250\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.2065 - accuracy: 0.5066\n",
            "Epoch 239/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.0999 - accuracy: 0.5257\n",
            "Epoch 240/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.0576 - accuracy: 0.5452\n",
            "Epoch 241/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1939 - accuracy: 0.5401\n",
            "Epoch 242/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.0249 - accuracy: 0.5530\n",
            "Epoch 243/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1406 - accuracy: 0.5048\n",
            "Epoch 244/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.1696 - accuracy: 0.5191\n",
            "Epoch 245/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.1102 - accuracy: 0.5379\n",
            "Epoch 246/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.0952 - accuracy: 0.5374\n",
            "Epoch 247/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.0674 - accuracy: 0.5280\n",
            "Epoch 248/250\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.2031 - accuracy: 0.5041\n",
            "Epoch 249/250\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.0962 - accuracy: 0.5484\n",
            "Epoch 250/250\n",
            "21/21 [==============================] - 1s 47ms/step - loss: 1.0472 - accuracy: 0.5639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kcd5CJEGG-S",
        "outputId": "9d76b1cf-6663-4e93-d2e8-b3a538223724"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images,test_labels)\n",
        "print(\"Now test accuracy is :\", test_accuracy)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 0s 5ms/step - loss: 1.9101 - accuracy: 0.2780\n",
            "Now test accuracy is : 0.27803468704223633\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}